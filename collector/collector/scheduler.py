"""
Collection Scheduler
ìˆ˜ì§‘ ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ë° ê´€ë¦¬
"""

import logging
import schedule
import time
import threading
import os
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
from core.database import db_service
from core.regtech_collector import regtech_collector
from api.secudium_api import collect_secudium_data
from .config import CollectorConfig

logger = logging.getLogger(__name__)


class CollectionScheduler:
    """ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.running = False
        self.scheduler_thread: Optional[threading.Thread] = None
        self.collection_stats = {
            "total_runs": 0,
            "successful_runs": 0,
            "failed_runs": 0,
            "last_run": None,
            "last_success": None,
            "last_failure": None,
            "consecutive_failures": 0,
            "adaptive_interval": CollectorConfig.COLLECTION_INTERVAL,
        }

        # ì ì‘í˜• ìŠ¤ì¼€ì¤„ë§ ì„¤ì •
        self.base_interval = CollectorConfig.COLLECTION_INTERVAL
        self.max_interval = 3600  # ìµœëŒ€ 1ì‹œê°„
        self.min_interval = 300  # ìµœì†Œ 5ë¶„
        self.failure_threshold = 3  # ì—°ì† ì‹¤íŒ¨ ì„ê³„ê°’

        # ìë™ ìˆ˜ì§‘ ë¹„í™œì„±í™” í”Œë˜ê·¸ (í™˜ê²½ë³€ìˆ˜)
        self.auto_collection_disabled = os.getenv("DISABLE_AUTO_COLLECTION", "false").lower() == "true"

    def start(self):
        """ì ì‘í˜• ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
        if self.running:
            logger.warning("âš ï¸ Scheduler is already running")
            return

        # ìë™ ìˆ˜ì§‘ì´ ë¹„í™œì„±í™”ëœ ê²½ìš°
        if self.auto_collection_disabled:
            logger.warning("âš ï¸ Auto-collection is DISABLED by environment variable")
            logger.info("âœ… Scheduler started in MANUAL-ONLY mode")
            self.running = True
            return

        logger.info(
            f"ğŸš€ Starting collection scheduler (24ì‹œê°„ ê°„ê²©)"
        )

        # 24ì‹œê°„ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ ì¶”ê°€
        self._setup_time_based_schedules()

        # ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤ë ˆë“œ ì‹œì‘
        self.running = True
        self.scheduler_thread = threading.Thread(
            target=self._scheduler_loop, daemon=True
        )
        self.scheduler_thread.start()

        logger.info("âœ… Adaptive collection scheduler started")

    def _setup_time_based_schedules(self):
        """24ì‹œê°„ ë‹¨ìˆœ ìŠ¤ì¼€ì¤„ ì„¤ì •"""
        # 24ì‹œê°„ë§ˆë‹¤ 1íšŒ ìˆ˜ì§‘ (ë§¤ì¼ ì˜¤ì „ 2ì‹œ)
        schedule.every().day.at("02:00").do(self._daily_collection, "ì¼ì¼ ì •ê¸°")

        logger.info("ğŸ“… 24ì‹œê°„ ìˆ˜ì§‘ ìŠ¤ì¼€ì¤„ ì„¤ì • ì™„ë£Œ (ë§¤ì¼ 02:00)")

    def _run_adaptive_collection(self) -> bool:
        """ì ì‘í˜• ìˆ˜ì§‘ ì‹¤í–‰"""
        try:
            start_time = datetime.now()
            self.collection_stats["total_runs"] += 1
            self.collection_stats["last_run"] = start_time.isoformat()

            logger.info(
                f"ğŸ“Š ì ì‘í˜• ìˆ˜ì§‘ ì‹œì‘ (ê°„ê²©: {self.collection_stats['adaptive_interval']}ì´ˆ)"
            )

            # ìŠ¤ì¼€ì¤„ ìˆ˜ì§‘: í˜ì´ì§€ 1ê°œë§Œ (2000ê°œ)
            collected_ips = regtech_collector.collect_blacklist_data(
                page_size=2000,
                start_date=None,
                end_date=None,
                max_pages=1
            )

            if collected_ips and len(collected_ips) > 0:
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                saved_count = db_service.save_blacklist_ips(collected_ips)

                # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
                execution_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)

                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                db_service.record_collection_history(
                    source="regtech",
                    success=True,
                    items_collected=saved_count,
                    execution_time_ms=execution_time_ms,
                )

                # ì„±ê³µ ì‹œ í†µê³„ ì—…ë°ì´íŠ¸
                self.collection_stats["successful_runs"] += 1
                self.collection_stats["last_success"] = start_time.isoformat()
                self.collection_stats["consecutive_failures"] = 0

                # ê°„ê²© ë‹¨ì¶• (ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë” ìì£¼ ìˆ˜ì§‘)
                self._adjust_interval_success()

                logger.info(f"âœ… ì ì‘í˜• ìˆ˜ì§‘ ì„±ê³µ: {saved_count}ê°œ IP ì €ì¥ ì™„ë£Œ")
                return True
            else:
                # ì‹¤íŒ¨ ì‹œ í†µê³„ ì—…ë°ì´íŠ¸
                self.collection_stats["failed_runs"] += 1
                self.collection_stats["last_failure"] = start_time.isoformat()
                self.collection_stats["consecutive_failures"] += 1

                # ê°„ê²© ì—°ì¥ (ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ëœ ìì£¼ ìˆ˜ì§‘)
                self._adjust_interval_failure()

                logger.warning(
                    f"âš ï¸ ì ì‘í˜• ìˆ˜ì§‘ ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ (ì—°ì† ì‹¤íŒ¨: {self.collection_stats['consecutive_failures']}íšŒ)"
                )
                return False

        except Exception as e:
            self.collection_stats["failed_runs"] += 1
            self.collection_stats["consecutive_failures"] += 1
            self.collection_stats["last_failure"] = datetime.now().isoformat()

            self._adjust_interval_failure()

            logger.error(f"âŒ ì ì‘í˜• ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return False

    def _adjust_interval_success(self):
        """ì„±ê³µ ì‹œ ê°„ê²© ì¡°ì •"""
        # ì„±ê³µí•˜ë©´ ê°„ê²©ì„ 80%ë¡œ ë‹¨ì¶• (ë” ìì£¼ ìˆ˜ì§‘)
        new_interval = max(
            self.min_interval, int(self.collection_stats["adaptive_interval"] * 0.8)
        )

        if new_interval != self.collection_stats["adaptive_interval"]:
            self.collection_stats["adaptive_interval"] = new_interval
            logger.info(f"â° ìˆ˜ì§‘ ê°„ê²© ë‹¨ì¶•: {new_interval}ì´ˆ (ì„±ê³µìœ¼ë¡œ ì¸í•œ ì¡°ì •)")
            self._reschedule_adaptive()

    def _adjust_interval_failure(self):
        """ì‹¤íŒ¨ ì‹œ ê°„ê²© ì¡°ì •"""
        # ì—°ì† ì‹¤íŒ¨ê°€ ì„ê³„ê°’ì„ ë„˜ìœ¼ë©´ ê°„ê²©ì„ 150%ë¡œ ì—°ì¥
        if self.collection_stats["consecutive_failures"] >= self.failure_threshold:
            new_interval = min(
                self.max_interval, int(self.collection_stats["adaptive_interval"] * 1.5)
            )

            if new_interval != self.collection_stats["adaptive_interval"]:
                self.collection_stats["adaptive_interval"] = new_interval
                logger.warning(f"â° ìˆ˜ì§‘ ê°„ê²© ì—°ì¥: {new_interval}ì´ˆ (ì—°ì† ì‹¤íŒ¨ë¡œ ì¸í•œ ì¡°ì •)")
                self._reschedule_adaptive()

    def _reschedule_adaptive(self):
        """ì ì‘í˜• ìŠ¤ì¼€ì¤„ ì¬ì„¤ì •"""
        # ê¸°ì¡´ ì ì‘í˜• ìŠ¤ì¼€ì¤„ ì œê±°
        schedule.clear("adaptive")

        # ìƒˆ ê°„ê²©ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ ì¬ì„¤ì •
        schedule.every(self.collection_stats["adaptive_interval"]).seconds.do(
            self._run_adaptive_collection
        ).tag("adaptive")

    def _daily_collection(self, schedule_name: str):
        """ì¼ì¼ ì •ê¸° ìˆ˜ì§‘ (24ì‹œê°„ë§ˆë‹¤)"""
        logger.info(f"ğŸ“† ì¼ì¼ ìˆ˜ì§‘ ì‹œì‘: {schedule_name}")

        start_time = datetime.now()

        try:
            # í˜ì´ì§€ 1ê°œ (2000ê°œ) ìˆ˜ì§‘
            collected_ips = regtech_collector.collect_blacklist_data(
                start_date=None,
                end_date=None,
                page_size=2000,
                max_pages=1,
            )

            if collected_ips and len(collected_ips) > 0:
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                saved_count = db_service.save_blacklist_ips(collected_ips)

                # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
                execution_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)

                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                db_service.record_collection_history(
                    source="regtech",
                    success=True,
                    items_collected=saved_count,
                    execution_time_ms=execution_time_ms,
                )

                logger.info(f"âœ… ì¼ì¼ ìˆ˜ì§‘ ì™„ë£Œ: {saved_count}ê°œ IP ì €ì¥")
            else:
                logger.warning(f"âš ï¸ ì¼ì¼ ìˆ˜ì§‘ ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ")

        except Exception as e:
            logger.error(f"âŒ ì¼ì¼ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            db_service.record_collection_history(
                source="regtech",
                success=False,
                items_collected=0,
                execution_time_ms=int((datetime.now() - start_time).total_seconds() * 1000),
                error_message=str(e),
            )

    def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
        if not self.running:
            return

        logger.info("ğŸ›‘ Stopping collection scheduler")
        self.running = False

        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=10)

        schedule.clear()
        logger.info("âœ… Collection scheduler stopped")

    def _scheduler_loop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ë£¨í”„"""
        while self.running:
            try:
                schedule.run_pending()
                time.sleep(1)
            except Exception as e:
                logger.error(f"âŒ Scheduler loop error: {e}")
                time.sleep(5)

    def _run_collection(self):
        """ìˆ˜ì§‘ ì‘ì—… ì‹¤í–‰"""
        start_time = datetime.now()

        try:
            logger.info("ğŸ“Š Starting scheduled collection")
            self.collection_stats["total_runs"] += 1
            self.collection_stats["last_run"] = start_time

            # REGTECH ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸° - ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ (ì¿ í‚¤ ê¸°ë°˜ ì¸ì¦)
            credentials = db_service.get_collection_credentials("REGTECH")

            if not credentials:
                logger.error("âŒ No REGTECH credentials found in database")
                logger.error("   Please save credentials via: POST /regtech/credentials")
                self._record_failure("No credentials in database")
                return

            regtech_id = credentials.get("username", "")
            regtech_pw = credentials.get("password", "")

            if not regtech_id or not regtech_pw:
                logger.error("âŒ Invalid REGTECH credentials in database")
                self._record_failure("Invalid credentials")
                return

            logger.info(f"ğŸ”‘ Using REGTECH credentials from database: {regtech_id}")

            # REGTECH ìˆ˜ì§‘ ì‹¤í–‰
            result = self._collect_regtech_data(regtech_id, regtech_pw)

            if result["success"]:
                self.collection_stats["successful_runs"] += 1
                self.collection_stats["last_success"] = start_time
                logger.info(f"âœ… Collection completed: {result['collected_count']} IPs")
            else:
                self._record_failure(result.get("error", "Unknown error"))

        except Exception as e:
            logger.error(f"âŒ Collection error: {e}")
            self._record_failure(str(e))

    def _collect_regtech_data(self, username: str, password: str, max_pages: int = 1) -> Dict[str, Any]:
        """REGTECH ë°ì´í„° ìˆ˜ì§‘

        Args:
            username: REGTECH ì‚¬ìš©ìëª…
            password: REGTECH ë¹„ë°€ë²ˆí˜¸
            max_pages: ìˆ˜ì§‘í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’ 1, ìˆ˜ë™ íŠ¸ë¦¬ê±°ëŠ” 50)
        """
        start_time = datetime.now()

        try:
            # ì¸ì¦
            if not regtech_collector.authenticate(username, password):
                return {
                    "success": False,
                    "error": "Authentication failed",
                    "collected_count": 0,
                }

            # ë°ì´í„° ìˆ˜ì§‘
            if max_pages == 1:
                logger.info("ğŸš€ REGTECH ìŠ¤ì¼€ì¤„ ìˆ˜ì§‘ (í˜ì´ì§€ 1ê°œ, 2000ê°œ)")
            else:
                logger.info(f"ğŸš€ REGTECH ìˆ˜ë™ ìˆ˜ì§‘ (ìµœëŒ€ {max_pages}í˜ì´ì§€, {max_pages * 2000}ê°œ)")

            collected_data = regtech_collector.collect_blacklist_data(
                page_size=2000,
                start_date=None,
                end_date=None,
                max_pages=max_pages,
            )

            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            saved_count = 0
            if collected_data:
                saved_count = db_service.save_blacklist_ips(collected_data)

            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time_ms = int(
                (datetime.now() - start_time).total_seconds() * 1000
            )

            # íˆìŠ¤í† ë¦¬ ê¸°ë¡
            db_service.record_collection_history(
                source="regtech",
                success=True,
                items_collected=saved_count,
                execution_time_ms=execution_time_ms,
            )

            return {
                "success": True,
                "collected_count": saved_count,
                "execution_time_ms": execution_time_ms,
            }

        except Exception as e:
            execution_time_ms = int(
                (datetime.now() - start_time).total_seconds() * 1000
            )

            # ì‹¤íŒ¨ íˆìŠ¤í† ë¦¬ ê¸°ë¡
            db_service.record_collection_history(
                source="regtech",
                success=False,
                items_collected=0,
                execution_time_ms=execution_time_ms,
                error_message=str(e),
            )

            return {"success": False, "error": str(e), "collected_count": 0}

    def _record_failure(self, error_message: str):
        """ì‹¤íŒ¨ ê¸°ë¡"""
        self.collection_stats["failed_runs"] += 1
        self.collection_stats["last_failure"] = datetime.now()
        logger.error(f"âŒ Collection failed: {error_message}")

    def get_status(self) -> Dict[str, Any]:
        """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë°˜í™˜"""
        return {
            "running": self.running,
            "next_run": self._get_next_run_time(),
            "stats": self.collection_stats.copy(),
            "config": {
                "interval_seconds": CollectorConfig.COLLECTION_INTERVAL,
                "batch_size": CollectorConfig.BATCH_SIZE,
                "max_retries": CollectorConfig.MAX_RETRY_ATTEMPTS,
            },
        }

    def _get_next_run_time(self) -> Optional[str]:
        """ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ë°˜í™˜"""
        if not self.running:
            return None

        try:
            next_job = schedule.next_run()
            if next_job:
                return next_job.isoformat()
        except Exception:
            pass

        return None

    def trigger_manual_collection(self) -> Dict[str, Any]:
        """ìˆ˜ë™ ìˆ˜ì§‘ íŠ¸ë¦¬ê±° (ì „ì²´ ìˆ˜ì§‘ - 50í˜ì´ì§€)"""
        try:
            logger.info("ğŸ”„ Manual collection triggered (ì „ì²´ ìˆ˜ì§‘ ëª¨ë“œ)")

            # ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ìˆ˜ì§‘ ì‹¤í–‰
            collection_thread = threading.Thread(
                target=self._run_manual_collection, daemon=True
            )
            collection_thread.start()

            return {"success": True, "message": "Manual collection started (full collection mode)"}

        except Exception as e:
            logger.error(f"âŒ Manual collection failed: {e}")
            return {"success": False, "error": str(e)}

    def _run_manual_collection(self):
        """ìˆ˜ë™ ìˆ˜ì§‘ ì‘ì—… ì‹¤í–‰ (ì „ì²´ ìˆ˜ì§‘ - 50í˜ì´ì§€)"""
        start_time = datetime.now()

        try:
            logger.info("ğŸ“Š Starting manual full collection (50 pages)")

            # REGTECH ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            credentials = db_service.get_collection_credentials("REGTECH")

            if not credentials:
                logger.error("âŒ No REGTECH credentials found in database")
                return

            regtech_id = credentials.get("username", "")
            regtech_pw = credentials.get("password", "")

            if not regtech_id or not regtech_pw:
                logger.error("âŒ Invalid REGTECH credentials in database")
                return

            logger.info(f"ğŸ”‘ Using REGTECH credentials from database: {regtech_id}")

            # REGTECH ì „ì²´ ìˆ˜ì§‘ ì‹¤í–‰ (50í˜ì´ì§€)
            result = self._collect_regtech_data(regtech_id, regtech_pw, max_pages=50)

            if result["success"]:
                logger.info(f"âœ… Manual full collection completed: {result['collected_count']} IPs")
            else:
                logger.error(f"âŒ Manual collection failed: {result.get('error', 'Unknown error')}")

        except Exception as e:
            logger.error(f"âŒ Manual collection error: {e}")

    def force_collection(self, source: str) -> Dict[str, Any]:
        """
        Force immediate collection for a specific source.

        Args:
            source: Source name ('REGTECH' or 'SECUDIUM')

        Returns:
            Collection result dictionary
        """
        start_time = datetime.now()

        try:
            logger.info(f"ğŸ”„ Force collection triggered for {source}")

            # Get credentials from database
            credentials = db_service.get_collection_credentials(source)

            if not credentials:
                error_msg = f"No {source} credentials found in database"
                logger.error(f"âŒ {error_msg}")
                return {
                    "success": False,
                    "error": error_msg,
                    "collected_count": 0
                }

            username = credentials.get("username", "")
            password = credentials.get("password", "")

            if not username or not password:
                error_msg = f"Invalid {source} credentials in database"
                logger.error(f"âŒ {error_msg}")
                return {
                    "success": False,
                    "error": error_msg,
                    "collected_count": 0
                }

            logger.info(f"ğŸ”‘ Using {source} credentials from database: {username}")

            # Route to appropriate collector
            if source == "REGTECH":
                result = self._collect_regtech_data(username, password, max_pages=50)
            elif source == "SECUDIUM":
                result = self._collect_secudium_data(username, password)
            else:
                return {
                    "success": False,
                    "error": f"Unknown source: {source}",
                    "collected_count": 0
                }

            return result

        except Exception as e:
            logger.error(f"âŒ Force collection error for {source}: {e}")
            return {
                "success": False,
                "error": str(e),
                "collected_count": 0
            }

    def _collect_secudium_data(self, username: str, password: str) -> Dict[str, Any]:
        """
        SECUDIUM ë°ì´í„° ìˆ˜ì§‘

        Args:
            username: SECUDIUM ì‚¬ìš©ìëª…
            password: SECUDIUM ë¹„ë°€ë²ˆí˜¸
        """
        start_time = datetime.now()

        try:
            logger.info("ğŸš€ SECUDIUM ìˆ˜ì§‘ ì‹œì‘")

            # SECUDIUM collector í˜¸ì¶œ
            credentials = {
                "username": username,
                "password": password
            }

            result = collect_secudium_data(db_service, credentials)

            # ìˆ˜ì§‘ ì„±ê³µ ì—¬ë¶€ í™•ì¸
            if result:
                collected_count = result.get("ips_collected", 0)
                reports_processed = result.get("reports_processed", 0)

                # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
                execution_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)

                # íˆìŠ¤í† ë¦¬ ê¸°ë¡
                db_service.record_collection_history(
                    source="secudium",
                    success=True,
                    items_collected=collected_count,
                    execution_time_ms=execution_time_ms,
                    details={
                        "reports_processed": reports_processed,
                        "ips_new": result.get("ips_new", 0),
                        "ips_duplicate": result.get("ips_duplicate", 0)
                    }
                )

                logger.info(f"âœ… SECUDIUM ìˆ˜ì§‘ ì™„ë£Œ: {collected_count}ê°œ IP ({reports_processed}ê°œ ë¦¬í¬íŠ¸)")

                return {
                    "success": True,
                    "collected_count": collected_count,
                    "execution_time_ms": execution_time_ms,
                    "reports_processed": reports_processed
                }
            else:
                logger.warning("âš ï¸ SECUDIUM ìˆ˜ì§‘ ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ")
                return {
                    "success": False,
                    "error": "No data collected",
                    "collected_count": 0
                }

        except Exception as e:
            execution_time_ms = int((datetime.now() - start_time).total_seconds() * 1000)

            # ì‹¤íŒ¨ íˆìŠ¤í† ë¦¬ ê¸°ë¡
            db_service.record_collection_history(
                source="secudium",
                success=False,
                items_collected=0,
                execution_time_ms=execution_time_ms,
                error_message=str(e)
            )

            logger.error(f"âŒ SECUDIUM ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "collected_count": 0
            }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
scheduler = CollectionScheduler()
