"""
REGTECH íŒŒì‹± ìœ í‹¸ë¦¬í‹°
ë‚ ì§œ, IP, êµ­ê°€ì½”ë“œ, HTML íŒŒì‹± í•¨ìˆ˜

Created: 2026-01-05 (Technical Debt Resolution)
Extracted from: regtech_collector.py
"""

import logging
import ipaddress
from datetime import datetime
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)


def parse_date(date_str: Any) -> Optional[str]:
    """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± - í–¥ìƒëœ ì²˜ë¦¬ ë° ë¡œê¹…"""
    if not date_str:
        return None

    logger.debug(f"ğŸ“… ë‚ ì§œ íŒŒì‹± ì‹œë„: '{date_str}' (íƒ€ì…: {type(date_str)})")

    date_str_clean = str(date_str).strip()

    date_formats = [
        "%Y-%m-%d",
        "%Y-%m-%d %H:%M:%S",
        "%Y/%m/%d",
        "%Y.%m.%d",
        "%d-%m-%Y",
        "%d/%m/%Y",
        "%d.%m.%Y",
        "%Y%m%d",
        "%m/%d/%Y",
        "%m-%d-%Y",
    ]

    for fmt in date_formats:
        try:
            parsed_date = datetime.strptime(date_str_clean, fmt)
            result = parsed_date.strftime("%Y-%m-%d")
            logger.debug(f"âœ… ë‚ ì§œ íŒŒì‹± ì„±ê³µ: '{date_str}' -> '{result}' (í˜•ì‹: {fmt})")
            return result
        except ValueError:
            continue

    logger.warning(f"âŒ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: '{date_str}' - ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹")
    return None


def is_valid_ip(ip_str: str) -> bool:
    """IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì‚¬ - í–¥ìƒëœ ê²€ì¦"""
    try:
        ip_obj = ipaddress.ip_address(ip_str.strip())

        if ip_obj.is_private or ip_obj.is_loopback or ip_obj.is_multicast:
            return False

        return True

    except ValueError:
        return False


def normalize_country_code(country_value: Any) -> Optional[str]:
    """êµ­ê°€ ì½”ë“œ ì •ê·œí™”"""
    if not country_value:
        return None

    country_str = str(country_value).upper().strip()

    country_mapping = {
        "KR": "KR",
        "KOREA": "KR",
        "í•œêµ­": "KR",
        "US": "US",
        "USA": "US",
        "UNITED STATES": "US",
        "CN": "CN",
        "CHINA": "CN",
        "ì¤‘êµ­": "CN",
        "JP": "JP",
        "JAPAN": "JP",
        "ì¼ë³¸": "JP",
    }

    return country_mapping.get(
        country_str, country_str[:2] if len(country_str) >= 2 else None
    )


def extract_country_info(cell_texts: List[str]) -> Optional[str]:
    """HTML í…Œì´ë¸” í–‰ì—ì„œ êµ­ê°€ ì •ë³´ ì¶”ì¶œ"""
    if not cell_texts:
        return None

    country_patterns = {
        "KR": ["KR", "Korea", "í•œêµ­", "South Korea", "Republic of Korea"],
        "US": ["US", "USA", "United States", "ë¯¸êµ­", "America"],
        "CN": ["CN", "China", "ì¤‘êµ­", "CHN"],
        "JP": ["JP", "Japan", "ì¼ë³¸", "JPN"],
        "RU": ["RU", "Russia", "ëŸ¬ì‹œì•„", "Russian"],
        "DE": ["DE", "Germany", "ë…ì¼", "German"],
        "FR": ["FR", "France", "í”„ë‘ìŠ¤", "French"],
        "GB": ["GB", "UK", "United Kingdom", "ì˜êµ­", "Britain"],
        "IN": ["IN", "India", "ì¸ë„", "Indian"],
    }

    for cell_text in cell_texts:
        if not cell_text or len(cell_text.strip()) < 2:
            continue

        cell_upper = cell_text.upper().strip()

        for country_code, patterns in country_patterns.items():
            for pattern in patterns:
                if pattern.upper() in cell_upper:
                    logger.debug(f"âœ… êµ­ê°€ ì •ë³´ ë°œê²¬: '{cell_text}' -> {country_code}")
                    return country_code

        if len(cell_text.strip()) == 2 and cell_text.strip().isalpha():
            country_code = cell_text.strip().upper()
            logger.debug(f"âœ… êµ­ê°€ ì½”ë“œ ë°œê²¬: {country_code}")
            return country_code

    return None


def determine_confidence(item: Dict[str, Any]) -> int:
    """ì‹ ë¢°ë„ ê²°ì • - í–¥ìƒëœ í‰ê°€"""
    base_confidence = 80

    threat_level = str(item.get("threatLevel", "medium")).lower()
    threat_adjustments = {"critical": 15, "high": 10, "medium": 0, "low": -10}

    confidence = base_confidence + threat_adjustments.get(threat_level, 0)

    if item.get("verified"):
        confidence += 5
    if item.get("reportCount", 0) > 10:
        confidence += 5

    return max(10, min(100, confidence))


def parse_html_response(html_content: str) -> List[Dict[str, Any]]:
    """HTML ì‘ë‹µì—ì„œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ IP ë°ì´í„° ì¶”ì¶œ"""
    try:
        soup = BeautifulSoup(html_content, "html.parser")
        collected_data = []

        rows = soup.find_all("tr")
        logger.info(f"ğŸ” Total {len(rows)} table rows found")

        for row in rows:
            cells = row.find_all("td")
            if len(cells) < 4:
                continue

            ip_text = cells[0].get_text(strip=True)
            if not is_valid_ip(ip_text):
                continue

            try:
                ip_address = ip_text
                country = cells[1].get_text(strip=True)

                reason_cell = cells[2]
                reason_link = reason_cell.find("a")
                if reason_link:
                    reason = reason_link.get_text(strip=True)
                else:
                    reason = reason_cell.get_text(strip=True)

                detection_date = parse_date(cells[3].get_text(strip=True))
                removal_date = (
                    parse_date(cells[4].get_text(strip=True))
                    if len(cells) > 4
                    else None
                )

                if not reason or reason == "-":
                    reason = "REGTECH Suspicious IP"

                item = {
                    "ip_address": ip_address,
                    "source": "REGTECH",
                    "reason": reason,
                    "confidence_level": 85,
                    "detection_count": 1,
                    "is_active": True,
                    "detection_date": detection_date,
                    "removal_date": removal_date,
                    "last_seen": datetime.now(),
                    "country": country,
                    "raw_data": {
                        "row_data": [c.get_text(strip=True) for c in cells[:6]],
                        "collection_timestamp": datetime.now().isoformat(),
                    },
                }
                collected_data.append(item)
                logger.debug(f"âœ… Extracted: {ip_address} ({reason})")

            except Exception as row_err:
                logger.warning(f"âš ï¸ Row parse error: {row_err}")

        logger.info(f"ğŸ“„ HTML parse complete: {len(collected_data)} IPs extracted")
        return collected_data

    except Exception as e:
        logger.error(f"âŒ HTML parse fatal error: {e}")
        return []
