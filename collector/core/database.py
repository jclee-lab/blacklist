"""
Database service for collector
ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ê´€ë¦¬ ì„œë¹„ìŠ¤
"""

import logging
import time
import ipaddress
import base64
import json
import os
from datetime import datetime, timedelta
from psycopg2.pool import SimpleConnectionPool
from contextlib import contextmanager
from typing import Optional, Dict, Any, List
from collector.config import CollectorConfig
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

logger = logging.getLogger(__name__)


class DatabaseService:
    """ê³ ì„±ëŠ¥ ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤ - ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬ ë° ìºì‹±"""

    def __init__(self):
        self.pool: Optional[SimpleConnectionPool] = None
        self._ip_cache: Dict[str, bool] = {}  # IP ì¡´ì¬ ì—¬ë¶€ ìºì‹œ
        self._cache_max_size = 1000000  # ìºì‹œ ìµœëŒ€ í¬ê¸° (100ë§Œê°œë¡œ ëŒ€í­ ì¦ê°€)
        self._batch_buffer: List[Dict[str, Any]] = []  # ë°°ì¹˜ ë²„í¼
        self._cipher_suite = None
        self._setup_decryption()
        # self._initialize_connection_pool()  # Lazy initialization

    def _setup_decryption(self):
        """ì•”í˜¸í™” í‚¤ ì„¤ì • (ë³µí˜¸í™”ìš©)"""
        try:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë§ˆìŠ¤í„° í‚¤ íšë“ (appê³¼ ë™ì¼í•œ í‚¤ ì‚¬ìš©)
            master_key = os.getenv("CREDENTIAL_MASTER_KEY")
            if not master_key:
                raise ValueError("CREDENTIAL_MASTER_KEY environment variable is required")

            # Salt (appê³¼ ë™ì¼)
            salt_env = os.getenv("ENCRYPTION_SALT")
            salt = salt_env.encode() if salt_env else b"blacklist-regtech-salt-2025"

            # PBKDF2ë¥¼ ì‚¬ìš©í•œ í‚¤ íŒŒìƒ
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=32,
                salt=salt,
                iterations=100000,
            )
            key = base64.urlsafe_b64encode(kdf.derive(master_key.encode()))
            self._cipher_suite = Fernet(key)

            logger.info("ğŸ” ë³µí˜¸í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ë³µí˜¸í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._cipher_suite = None

    def _decrypt_password(self, encrypted_data: str) -> str:
        """ì•”í˜¸í™”ëœ ë¹„ë°€ë²ˆí˜¸ ë³µí˜¸í™”"""
        try:
            if not self._cipher_suite:
                logger.error("âŒ ë³µí˜¸í™” ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return encrypted_data

            decoded = base64.b64decode(encrypted_data.encode())
            decrypted = self._cipher_suite.decrypt(decoded)
            decrypted_json = decrypted.decode()

            # JSON íŒŒì‹±í•˜ì—¬ password ì¶”ì¶œ
            credential_data = json.loads(decrypted_json)
            return credential_data.get("password", "")
        except Exception as e:
            logger.error(f"âŒ ë¹„ë°€ë²ˆí˜¸ ë³µí˜¸í™” ì‹¤íŒ¨: {e}")
            return encrypted_data

    def _initialize_connection_pool(self):
        """ì—°ê²° í’€ ì´ˆê¸°í™” - ê³ ì„±ëŠ¥ ì„¤ì •"""
        try:
            self.pool = SimpleConnectionPool(
                minconn=2,  # ìµœì†Œ ì—°ê²° ìˆ˜ ì¦ê°€
                maxconn=20,  # ìµœëŒ€ ì—°ê²° ìˆ˜ ì¦ê°€
                host=CollectorConfig.POSTGRES_HOST,
                port=CollectorConfig.POSTGRES_PORT,
                database=CollectorConfig.POSTGRES_DB,
                user=CollectorConfig.POSTGRES_USER,
                password=CollectorConfig.POSTGRES_PASSWORD,
                # ì„±ëŠ¥ ìµœì í™” íŒŒë¼ë¯¸í„°
                **{
                    "connect_timeout": 10,
                    "application_name": "blacklist_collector_optimized",
                },
            )
            logger.info("âœ… ê³ ì„±ëŠ¥ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ í’€ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    @contextmanager
    def get_connection(self):
        """ìµœì í™”ëœ ì—°ê²° í’€ì—ì„œ ì—°ê²° ê°€ì ¸ì˜¤ê¸°"""
        if self.pool is None:
            self._initialize_connection_pool()

        if self.pool is None:
            logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            raise RuntimeError("Database connection pool is not initialized")

        conn = None
        try:
            conn = self.pool.getconn()
            if conn is None:
                raise RuntimeError("Failed to get connection from pool")
            # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
            conn.autocommit = False
            yield conn
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
            raise
        finally:
            if conn and self.pool:
                self.pool.putconn(conn)

    def test_connection(self) -> bool:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT 1")
                result = cursor.fetchone()
                cursor.close()
                return result[0] == 1
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    def get_collection_credentials(self, service_name: str) -> Optional[Dict[str, Any]]:
        """ìˆ˜ì§‘ ì„œë¹„ìŠ¤ ì¸ì¦ ì •ë³´ ì¡°íšŒ - ì•”í˜¸í™”ëœ ë¹„ë°€ë²ˆí˜¸ ìë™ ë³µí˜¸í™”"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    SELECT service_name, username, password, encrypted, 
                           enabled, collection_interval, last_collection
                    FROM collection_credentials
                    WHERE service_name = %s
                """,
                    (service_name,),
                )
                result = cursor.fetchone()
                cursor.close()

                if result:
                    (
                        service_name,
                        username,
                        password,
                        encrypted,
                        enabled,
                        interval,
                        last_collection,
                    ) = result

                    # ì•”í˜¸í™”ëœ ê²½ìš° ë³µí˜¸í™”
                    final_password = password
                    if encrypted and password:
                        logger.info(f"ğŸ” {service_name} ì•”í˜¸í™”ëœ ë¹„ë°€ë²ˆí˜¸ ë³µí˜¸í™” ì¤‘...")
                        final_password = self._decrypt_password(password)

                    return {
                        "service_name": service_name,
                        "username": username,
                        "password": final_password,
                        "enabled": enabled,
                        "collection_interval": interval,
                        "last_collection": last_collection,
                    }

                return None
        except Exception as e:
            logger.error(f"ì¸ì¦ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ {service_name}: {e}")
            return None

    def save_blacklist_ips(self, ip_data: List[Dict[str, Any]]) -> Dict[str, int]:
        """ìµœì í™”ëœ ë¸”ë™ë¦¬ìŠ¤íŠ¸ IP ë°ì´í„° ì €ì¥ - ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬

        Returns:
            Dict with 'total', 'new_count', 'updated_count' keys
        """
        if not ip_data:
            return {"total": 0, "new_count": 0, "updated_count": 0}

        saved_count = 0
        new_count = 0
        updated_count = 0
        processing_start = time.time()

        try:
            logger.info(f"ğŸš€ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(ip_data)}ê°œ IP")

            # 1ë‹¨ê³„: ì‚¬ì„¤ IP ë° ì˜¤íƒ í•„í„°ë§
            filtered_ips, excluded_count = self._filter_invalid_ips(ip_data)
            logger.info(f"ğŸ›¡ï¸ ì˜¤íƒ í•„í„°ë§ ì™„ë£Œ: {excluded_count}ê°œ ì œì™¸ (ì‚¬ì„¤ IP, ì˜ëª»ëœ í˜•ì‹ ë“±)")

            if not filtered_ips:
                logger.warning("âš ï¸ í•„í„°ë§ í›„ ìœ íš¨í•œ IPê°€ ì—†ìŠµë‹ˆë‹¤")
                return {"total": 0, "new_count": 0, "updated_count": 0}

            # 2ë‹¨ê³„: ë©”ëª¨ë¦¬ ìµœì í™”ëœ ì¤‘ë³µ ì œê±°
            unique_ips = self._memory_optimized_dedup(filtered_ips)
            logger.info(f"ğŸ“Š ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(unique_ips)}ê°œ ê³ ìœ  IP")

            # 3ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ê¸°ì¡´ IP ë°°ì¹˜ í™•ì¸ (ì‹ ê·œ/ì¤‘ë³µ êµ¬ë¶„ìš©)
            existing_ips = self._batch_check_existing_ips([item["ip_address"] for item in unique_ips])

            new_count = len([ip for ip in unique_ips if ip["ip_address"] not in existing_ips])
            updated_count = len(existing_ips)

            logger.info(f"ğŸ“Š ì‹ ê·œ: {new_count}ê°œ, ì¤‘ë³µ(ì—…ë°ì´íŠ¸): {updated_count}ê°œ")

            if not unique_ips:
                logger.info("âœ… ì²˜ë¦¬í•  IPê°€ ì—†ìŠµë‹ˆë‹¤")
                return {"total": 0, "new_count": 0, "updated_count": 0}

            # 4ë‹¨ê³„: ëŒ€ìš©ëŸ‰ ë°°ì¹˜ UPSERT (ì‹ ê·œ+ì¤‘ë³µ ëª¨ë‘ ì²˜ë¦¬)
            with self.get_connection() as conn:
                cursor = conn.cursor()

                # ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” (íŠ¸ëœì­ì…˜ ì „ì— ì„¤ì •)
                cursor.execute("SET work_mem = '256MB'")
                cursor.execute("SET maintenance_work_mem = '256MB'")
                cursor.execute("SET synchronous_commit = off")

                # íŠ¸ëœì­ì…˜ ì‹œì‘
                cursor.execute("BEGIN")

                # ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ (ì²­í¬ ë‹¨ìœ„)
                chunk_size = CollectorConfig.BATCH_SIZE
                total_chunks = (len(unique_ips) + chunk_size - 1) // chunk_size

                for chunk_idx, chunk in enumerate(self._get_batches(unique_ips, chunk_size)):
                    chunk_saved = self._optimized_batch_insert(cursor, chunk)
                    saved_count += chunk_saved

                    # ì§„í–‰ ìƒí™© ë¡œê¹…
                    if chunk_idx % 10 == 0:
                        logger.info(f"ğŸ“ˆ ì²˜ë¦¬ ì§„í–‰ë¥ : {chunk_idx + 1}/{total_chunks} ì²­í¬ ì™„ë£Œ")

                # ì»¤ë°‹ ì „ ìµœì¢… ê²€ì¦
                cursor.execute(
                    "SELECT COUNT(*) FROM blacklist_ips WHERE created_at >= %s",
                    (datetime.now() - timedelta(minutes=5),),
                )
                # recent_count = cursor.fetchone()[0]

                conn.commit()
                cursor.close()

                processing_time = time.time() - processing_start
                logger.info(
                    f"âœ… ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ì‹ ê·œ {new_count}ê°œ, ì¤‘ë³µ {updated_count}ê°œ ({processing_time:.2f}ì´ˆ)"
                )

        except Exception as e:
            logger.error(f"âŒ ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        return {
            "total": saved_count,
            "new_count": new_count,
            "updated_count": updated_count,
        }

    def _filter_invalid_ips(self, ip_data: List[Dict[str, Any]]) -> tuple[List[Dict[str, Any]], int]:
        """
        ì‚¬ì„¤ IP ë° ì˜¤íƒ IP í•„í„°ë§

        ì œì™¸ ëŒ€ìƒ:
        - ì‚¬ì„¤ IP ëŒ€ì—­ (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16)
        - Loopback (127.0.0.0/8)
        - Link-local (169.254.0.0/16)
        - ì˜ëª»ëœ IP í˜•ì‹
        - Reserved IP
        - í•´ì œì¼(removal_date)ì´ ì´ë¯¸ ì§€ë‚œ IP
        """
        valid_ips = []
        excluded_count = 0
        expired_count = 0
        today = datetime.now().date()

        for item in ip_data:
            ip_str = item.get("ip_address")
            if not ip_str:
                excluded_count += 1
                continue

            try:
                ip = ipaddress.ip_address(ip_str)

                # ì‚¬ì„¤ IP, Loopback, Link-local, Reserved ì œì™¸
                if ip.is_private or ip.is_loopback or ip.is_link_local or ip.is_reserved:
                    excluded_count += 1
                    logger.debug(f"ğŸš« ì œì™¸ëœ IP: {ip_str} (ì‚¬ì„¤/ì˜ˆì•½ ëŒ€ì—­)")
                    continue

                # í•´ì œì¼ì´ ì´ë¯¸ ì§€ë‚œ IP ì œì™¸ (ì˜¤ëŠ˜ í•´ì œë˜ëŠ” IPëŠ” í¬í•¨)
                removal_date = self._convert_date_string(item.get("removal_date"))
                if removal_date and removal_date < today:
                    expired_count += 1
                    logger.debug(f"ğŸš« ì œì™¸ëœ IP: {ip_str} (í•´ì œì¼ {removal_date} ê²½ê³¼)")
                    continue

                # ìœ íš¨í•œ ê³µì¸ IP
                valid_ips.append(item)

            except ValueError:
                # ì˜ëª»ëœ IP í˜•ì‹
                excluded_count += 1
                logger.debug(f"ğŸš« ì œì™¸ëœ IP: {ip_str} (ì˜ëª»ëœ í˜•ì‹)")
                continue

        logger.info(
            f"ğŸ“Š IP í•„í„°ë§: {len(valid_ips)}ê°œ ìœ íš¨, {excluded_count}ê°œ ì œì™¸ (ì‚¬ì„¤/í˜•ì‹), {expired_count}ê°œ ì œì™¸ (í•´ì œì¼ ê²½ê³¼)"
        )
        return valid_ips, excluded_count + expired_count

    def _memory_optimized_dedup(self, ip_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ë©”ëª¨ë¦¬ ìµœì í™”ëœ ì¤‘ë³µ ì œê±° - ëŒ€ìš©ëŸ‰ ë°ì´í„° ì§€ì›"""
        seen_ips = set()
        unique_data = []

        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì¤‘ë³µ ì œê±°
        for item in ip_data:
            ip_addr = item.get("ip_address")
            if ip_addr and ip_addr not in seen_ips:
                seen_ips.add(ip_addr)
                unique_data.append(item)

                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ
                if len(unique_data) >= self._cache_max_size:
                    logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ì œí•œì— ë„ë‹¬: {len(unique_data)}ê°œ IPë¡œ ì œí•œ")
                    break

        return unique_data

    def _batch_check_existing_ips(self, ip_addresses: List[str]) -> set:
        """ë°°ì¹˜ë¡œ ê¸°ì¡´ IP ì¡´ì¬ ì—¬ë¶€ í™•ì¸ - ì„±ëŠ¥ ìµœì í™”"""
        if not ip_addresses:
            return set()

        existing_ips = set()

        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()

                # ëŒ€ìš©ëŸ‰ IN ì ˆ ìµœì í™”
                batch_size = 1000
                for batch in self._get_batches(ip_addresses, batch_size):
                    placeholders = ",".join(["%s"] * len(batch))
                    query = f"""
                        SELECT DISTINCT ip_address 
                        FROM blacklist_ips 
                        WHERE ip_address IN ({placeholders})
                    """
                    cursor.execute(query, batch)
                    results = cursor.fetchall()
                    existing_ips.update(row[0] for row in results)

                cursor.close()

        except Exception as e:
            logger.error(f"ê¸°ì¡´ IP í™•ì¸ ì‹¤íŒ¨: {e}")

        return existing_ips

    def _get_batches(self, data: List[Any], batch_size: int):
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ë¶„í• """
        for i in range(0, len(data), batch_size):
            yield data[i : i + batch_size]

    def _optimized_batch_insert(self, cursor, batch: List[Dict[str, Any]]) -> int:
        """ìµœì í™”ëœ ë°°ì¹˜ ì‚½ì… - ì§ì ‘ executemany ì‚¬ìš©"""
        if not batch:
            return 0

        # ë°”ë¡œ fallback ë©”ì„œë“œ ì‚¬ìš© (COPYëŠ” ON CONFLICT ì§€ì› ì•ˆí•¨)
        return self._fallback_batch_insert(cursor, batch)

    def _fallback_batch_insert(self, cursor, batch: List[Dict[str, Any]]) -> int:
        """ëŒ€ì²´ ë°°ì¹˜ ì‚½ì… ë°©ì‹ - executemany (raw_data JSONB í¬í•¨)"""
        values = []
        for item in batch:
            # raw_dataë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            raw_data_value = item.get("raw_data")
            if raw_data_value and isinstance(raw_data_value, dict):
                raw_data_json = json.dumps(raw_data_value, ensure_ascii=False)
            elif isinstance(raw_data_value, str):
                raw_data_json = raw_data_value
            else:
                # raw_dataê°€ ì—†ìœ¼ë©´ ì›ë³¸ itemì—ì„œ ê´€ë ¨ ë°ì´í„° ì¶”ì¶œí•˜ì—¬ ì €ì¥
                raw_data_json = json.dumps(
                    {
                        "ip_address": item.get("ip_address"),
                        "country": item.get("country"),
                        "reason": item.get("reason"),
                        "detection_date": str(item.get("detection_date")) if item.get("detection_date") else None,
                        "removal_date": str(item.get("removal_date")) if item.get("removal_date") else None,
                        "confidence_level": item.get("confidence_level"),
                        "collection_timestamp": datetime.now().isoformat(),
                    },
                    ensure_ascii=False,
                )

            # í•´ì œì¼(removal_date) ê¸°ì¤€ìœ¼ë¡œ is_active ê²°ì • (ì˜¤ëŠ˜ í•´ì œ IPëŠ” ì•„ì§ í™œì„±)
            removal_date = self._convert_date_string(item.get("removal_date"))
            if removal_date and removal_date < datetime.now().date():
                is_active = False  # í•´ì œì¼ì´ ì§€ë‚¬ìœ¼ë©´ ë¹„í™œì„±
            else:
                is_active = item.get("is_active", True)

            values.append(
                (
                    item.get("ip_address"),
                    item.get("reason", "Blacklist IP"),
                    item.get("source", "COLLECTOR"),
                    self._convert_confidence_to_int(item.get("confidence_level", 50)),
                    item.get("detection_count", 1),
                    item.get("last_seen", datetime.now()),
                    is_active,  # í•´ì œì¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ëœ ê°’ ì‚¬ìš©
                    datetime.now(),
                    datetime.now(),
                    self._convert_date_string(item.get("detection_date")),
                    removal_date,
                    item.get("country"),
                    raw_data_json,  # raw_data JSONB ì¶”ê°€
                    item.get("data_source", "REGTECH"),  # data_source ì»¬ëŸ¼ ì¶”ê°€
                )
            )

        try:
            cursor.executemany(
                """
                INSERT INTO blacklist_ips
                (ip_address, reason, source, confidence_level,
                 detection_count, last_seen, is_active, created_at, updated_at,
                 detection_date, removal_date, country, raw_data, data_source)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (ip_address, source) DO UPDATE SET
                    detection_count = blacklist_ips.detection_count + 1,
                    last_seen = EXCLUDED.last_seen,
                    updated_at = EXCLUDED.updated_at,
                    reason = EXCLUDED.reason,
                    removal_date = COALESCE(EXCLUDED.removal_date, blacklist_ips.removal_date),
                    is_active = CASE 
                        WHEN COALESCE(EXCLUDED.removal_date, blacklist_ips.removal_date) < CURRENT_DATE 
                        THEN false 
                        ELSE EXCLUDED.is_active 
                    END,
                    country = COALESCE(EXCLUDED.country, blacklist_ips.country),
                    raw_data = EXCLUDED.raw_data,
                    data_source = COALESCE(blacklist_ips.data_source, EXCLUDED.data_source)
            """,
                values,
            )
            return cursor.rowcount
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì‚½ì… ì‹¤íŒ¨: {e}")
            return 0

    def _convert_confidence_to_int(self, confidence_value) -> int:
        """ì‹ ë¢°ë„ ê°’ì„ ì •ìˆ˜ë¡œ ë³€í™˜"""
        if isinstance(confidence_value, int):
            return confidence_value
        elif isinstance(confidence_value, str):
            confidence_mapping = {
                "high": 90,
                "medium": 50,
                "low": 10,
                "critical": 95,
                "unknown": 5,
            }
            return confidence_mapping.get(confidence_value.lower(), 50)
        return 50

    def _convert_date_string(self, date_str):
        """ë‚ ì§œ ë¬¸ìì—´ì„ date ê°ì²´ë¡œ ë³€í™˜"""
        if not date_str or not isinstance(date_str, str):
            return None

        try:
            return datetime.strptime(date_str, "%Y-%m-%d").date()
        except Exception:
            return None

    def record_collection_history(
        self,
        source: str,
        success: bool,
        items_collected: int,
        execution_time_ms: int,
        error_message: Optional[str] = None,
        new_count: int = 0,
        updated_count: int = 0,
    ):
        try:
            details = json.dumps({"new_count": new_count, "updated_count": updated_count})
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    INSERT INTO collection_history
                    (service_name, success, items_collected, execution_time_ms, 
                     error_message, collection_date, collection_type, details)
                    VALUES (%s, %s, %s, %s, %s, CURRENT_TIMESTAMP, 'manual', %s)
                """,
                    (
                        source,
                        success,
                        items_collected,
                        execution_time_ms,
                        error_message or "",
                        details,
                    ),
                )
                conn.commit()
                cursor.close()
                logger.info(f"ğŸ“Š ìˆ˜ì§‘ íˆìŠ¤í† ë¦¬ ê¸°ë¡: {source} (ì‹ ê·œ: {new_count}, ì¤‘ë³µ: {updated_count})")
        except Exception as e:
            logger.error(f"âŒ ìˆ˜ì§‘ íˆìŠ¤í† ë¦¬ ê¸°ë¡ ì‹¤íŒ¨: {e}")

    def get_total_ip_count(self) -> int:
        """ì „ì²´ IP ê°œìˆ˜ ë°˜í™˜ - ìµœì´ˆ ìˆ˜ì§‘ ì—¬ë¶€ í™•ì¸ìš©"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM blacklist_ips")
                result = cursor.fetchone()
                cursor.close()
                return result[0] if result else 0
        except Exception as e:
            logger.error(f"ì´ IP ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0

    def get_collection_stats(self) -> Dict[str, Any]:
        """ê³ ì„±ëŠ¥ ìˆ˜ì§‘ í†µê³„ ì¡°íšŒ"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()

                # ë³‘ë ¬ í†µê³„ ì¿¼ë¦¬ ìµœì í™”
                cursor.execute(
                    """
                    WITH stats AS (
                        SELECT 
                            COUNT(*) as total_ips,
                            COUNT(*) FILTER (WHERE is_active = true) as active_ips,
                            MAX(created_at) as latest_collection
                        FROM blacklist_ips
                    ),
                    source_stats AS (
                        SELECT json_object_agg(COALESCE(data_source, 'UNKNOWN'), cnt) as source_breakdown
                        FROM (
                            SELECT data_source, COUNT(*) as cnt 
                            FROM blacklist_ips 
                            GROUP BY data_source
                        ) s
                    )
                    SELECT s.total_ips, s.active_ips, s.latest_collection, 
                           ss.source_breakdown
                    FROM stats s CROSS JOIN source_stats ss
                """
                )

                result = cursor.fetchone()
                cursor.close()

                if result:
                    return {
                        "total_ips": result[0],
                        "active_ips": result[1],
                        "latest_collection": result[2],
                        "source_breakdown": result[3] or {},
                        "cache_size": len(self._ip_cache),
                        "performance_mode": "optimized",
                    }

        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        return {}


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
db_service = DatabaseService()
