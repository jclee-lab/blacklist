"""
Database service for collector
Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Î∞è Í¥ÄÎ¶¨ ÏÑúÎπÑÏä§
"""

import logging
import psycopg2
import time
import ipaddress
import base64
import json
import os
from datetime import datetime, timedelta
from psycopg2.pool import SimpleConnectionPool
from contextlib import contextmanager
from typing import Optional, Dict, Any, List
from collector.config import CollectorConfig
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

logger = logging.getLogger(__name__)


class DatabaseService:
    """Í≥†ÏÑ±Îä• Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÑúÎπÑÏä§ ÌÅ¥ÎûòÏä§ - ÏµúÏ†ÅÌôîÎêú Î∞∞Ïπò Ï≤òÎ¶¨ Î∞è Ï∫êÏã±"""

    def __init__(self):
        self.pool: Optional[SimpleConnectionPool] = None
        self._ip_cache: Dict[str, bool] = {}  # IP Ï°¥Ïû¨ Ïó¨Î∂Ä Ï∫êÏãú
        self._cache_max_size = 1000000  # Ï∫êÏãú ÏµúÎåÄ ÌÅ¨Í∏∞ (100ÎßåÍ∞úÎ°ú ÎåÄÌè≠ Ï¶ùÍ∞Ä)
        self._batch_buffer: List[Dict[str, Any]] = []  # Î∞∞Ïπò Î≤ÑÌçº
        self._cipher_suite = None
        self._setup_decryption()
        self._initialize_connection_pool()

    def _setup_decryption(self):
        """ÏïîÌò∏Ìôî ÌÇ§ ÏÑ§Ï†ï (Î≥µÌò∏ÌôîÏö©)"""
        try:
            # ÌôòÍ≤ΩÎ≥ÄÏàòÏóêÏÑú ÎßàÏä§ÌÑ∞ ÌÇ§ ÌöçÎìù (appÍ≥º ÎèôÏùºÌïú ÌÇ§ ÏÇ¨Ïö©)
            master_key = os.getenv("CREDENTIAL_MASTER_KEY")
            if not master_key:
                master_key = "default-blacklist-credential-master-key-2025"

            # Salt (appÍ≥º ÎèôÏùº)
            salt = b'blacklist-regtech-salt-2025'

            # PBKDF2Î•º ÏÇ¨Ïö©Ìïú ÌÇ§ ÌååÏÉù
            kdf = PBKDF2HMAC(
                algorithm=hashes.SHA256(),
                length=32,
                salt=salt,
                iterations=100000,
            )
            key = base64.urlsafe_b64encode(kdf.derive(master_key.encode()))
            self._cipher_suite = Fernet(key)

            logger.info("üîê Î≥µÌò∏Ìôî ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
        except Exception as e:
            logger.error(f"‚ùå Î≥µÌò∏Ìôî ÏãúÏä§ÌÖú Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            self._cipher_suite = None

    def _decrypt_password(self, encrypted_data: str) -> str:
        """ÏïîÌò∏ÌôîÎêú ÎπÑÎ∞ÄÎ≤àÌò∏ Î≥µÌò∏Ìôî"""
        try:
            if not self._cipher_suite:
                logger.error("‚ùå Î≥µÌò∏Ìôî ÏãúÏä§ÌÖúÏù¥ Ï¥àÍ∏∞ÌôîÎêòÏßÄ ÏïäÏùå")
                return encrypted_data

            decoded = base64.b64decode(encrypted_data.encode())
            decrypted = self._cipher_suite.decrypt(decoded)
            decrypted_json = decrypted.decode()

            # JSON ÌååÏã±ÌïòÏó¨ password Ï∂îÏ∂ú
            credential_data = json.loads(decrypted_json)
            return credential_data.get("password", "")
        except Exception as e:
            logger.error(f"‚ùå ÎπÑÎ∞ÄÎ≤àÌò∏ Î≥µÌò∏Ìôî Ïã§Ìå®: {e}")
            return encrypted_data

    def _initialize_connection_pool(self):
        """Ïó∞Í≤∞ ÌíÄ Ï¥àÍ∏∞Ìôî - Í≥†ÏÑ±Îä• ÏÑ§Ï†ï"""
        try:
            self.pool = SimpleConnectionPool(
                minconn=2,  # ÏµúÏÜå Ïó∞Í≤∞ Ïàò Ï¶ùÍ∞Ä
                maxconn=20,  # ÏµúÎåÄ Ïó∞Í≤∞ Ïàò Ï¶ùÍ∞Ä
                host=CollectorConfig.POSTGRES_HOST,
                port=CollectorConfig.POSTGRES_PORT,
                database=CollectorConfig.POSTGRES_DB,
                user=CollectorConfig.POSTGRES_USER,
                password=CollectorConfig.POSTGRES_PASSWORD,
                # ÏÑ±Îä• ÏµúÏ†ÅÌôî ÌååÎùºÎØ∏ÌÑ∞
                **{
                    "connect_timeout": 10,
                    "application_name": "blacklist_collector_optimized",
                },
            )
            logger.info("‚úÖ Í≥†ÏÑ±Îä• Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ ÌíÄ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
        except Exception as e:
            logger.error(f"‚ùå Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌíÄ Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            raise

    @contextmanager
    def get_connection(self):
        """ÏµúÏ†ÅÌôîÎêú Ïó∞Í≤∞ ÌíÄÏóêÏÑú Ïó∞Í≤∞ Í∞ÄÏ†∏Ïò§Í∏∞"""
        conn = None
        try:
            conn = self.pool.getconn()
            # ÏÑ±Îä• ÏµúÏ†ÅÌôî ÏÑ§Ï†ï
            conn.autocommit = False
            yield conn
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Ïò§Î•ò: {e}")
            raise
        finally:
            if conn:
                self.pool.putconn(conn)

    def test_connection(self) -> bool:
        """Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ ÌÖåÏä§Ìä∏"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT 1")
                result = cursor.fetchone()
                cursor.close()
                return result[0] == 1
        except Exception as e:
            logger.error(f"Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ ÌÖåÏä§Ìä∏ Ïã§Ìå®: {e}")
            return False

    def get_collection_credentials(self, service_name: str) -> Optional[Dict[str, str]]:
        """ÏàòÏßë ÏÑúÎπÑÏä§ Ïù∏Ï¶ù Ï†ïÎ≥¥ Ï°∞Ìöå - ÏïîÌò∏ÌôîÎêú ÎπÑÎ∞ÄÎ≤àÌò∏ ÏûêÎèô Î≥µÌò∏Ìôî"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    SELECT username, password, encrypted
                    FROM collection_credentials
                    WHERE service_name = %s AND is_active = TRUE
                """,
                    (service_name,),
                )
                result = cursor.fetchone()
                cursor.close()

                if result:
                    username, password, encrypted = result

                    # ÏïîÌò∏ÌôîÎêú Í≤ΩÏö∞ Î≥µÌò∏Ìôî
                    if encrypted and password:
                        logger.info(f"üîê {service_name} ÏïîÌò∏ÌôîÎêú ÎπÑÎ∞ÄÎ≤àÌò∏ Î≥µÌò∏Ìôî Ï§ë...")
                        decrypted_password = self._decrypt_password(password)
                        return {"username": username, "password": decrypted_password}
                    else:
                        # ÌèâÎ¨∏Ïù∏ Í≤ΩÏö∞ Í∑∏ÎåÄÎ°ú Î∞òÌôò
                        return {"username": username, "password": password}

                return None
        except Exception as e:
            logger.error(f"Ïù∏Ï¶ù Ï†ïÎ≥¥ Ï°∞Ìöå Ïã§Ìå® {service_name}: {e}")
            return None

    def save_blacklist_ips(self, ip_data: List[Dict[str, Any]]) -> int:
        """ÏµúÏ†ÅÌôîÎêú Î∏îÎûôÎ¶¨Ïä§Ìä∏ IP Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• - ÎåÄÏö©Îüâ Î∞∞Ïπò Ï≤òÎ¶¨"""
        if not ip_data:
            return 0

        saved_count = 0
        processing_start = time.time()

        try:
            logger.info(f"üöÄ ÎåÄÏö©Îüâ Î∞∞Ïπò Ï≤òÎ¶¨ ÏãúÏûë: {len(ip_data)}Í∞ú IP")

            # 1Îã®Í≥Ñ: ÏÇ¨ÏÑ§ IP Î∞è Ïò§ÌÉê ÌïÑÌÑ∞ÎßÅ
            filtered_ips, excluded_count = self._filter_invalid_ips(ip_data)
            logger.info(f"üõ°Ô∏è Ïò§ÌÉê ÌïÑÌÑ∞ÎßÅ ÏôÑÎ£å: {excluded_count}Í∞ú Ï†úÏô∏ (ÏÇ¨ÏÑ§ IP, ÏûòÎ™ªÎêú ÌòïÏãù Îì±)")

            if not filtered_ips:
                logger.warning("‚ö†Ô∏è ÌïÑÌÑ∞ÎßÅ ÌõÑ Ïú†Ìö®Ìïú IPÍ∞Ä ÏóÜÏäµÎãàÎã§")
                return 0

            # 2Îã®Í≥Ñ: Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôîÎêú Ï§ëÎ≥µ Ï†úÍ±∞
            unique_ips = self._memory_optimized_dedup(filtered_ips)
            logger.info(f"üìä Ï§ëÎ≥µ Ï†úÍ±∞ ÏôÑÎ£å: {len(unique_ips)}Í∞ú Í≥†Ïú† IP")

            # 3Îã®Í≥Ñ: Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í∏∞Ï°¥ IP Î∞∞Ïπò ÌôïÏù∏
            existing_ips = self._batch_check_existing_ips(
                [item["ip_address"] for item in unique_ips]
            )
            new_ips = [
                item for item in unique_ips if item["ip_address"] not in existing_ips
            ]
            logger.info(f"üìä Ïã†Í∑ú IP ÌïÑÌÑ∞ÎßÅ: {len(new_ips)}Í∞ú Ïã†Í∑ú IP")

            if not new_ips:
                logger.info("‚úÖ Ï≤òÎ¶¨Ìï† Ïã†Í∑ú IPÍ∞Ä ÏóÜÏäµÎãàÎã§")
                return 0

            # 4Îã®Í≥Ñ: ÎåÄÏö©Îüâ Î∞∞Ïπò ÏÇΩÏûÖ
            with self.get_connection() as conn:
                cursor = conn.cursor()

                # Î∞∞Ïπò Ï≤òÎ¶¨ ÏµúÏ†ÅÌôî (Ìä∏ÎûúÏû≠ÏÖò Ï†ÑÏóê ÏÑ§Ï†ï)
                cursor.execute("SET work_mem = '256MB'")
                cursor.execute("SET maintenance_work_mem = '256MB'")
                cursor.execute("SET synchronous_commit = off")

                # Ìä∏ÎûúÏû≠ÏÖò ÏãúÏûë
                cursor.execute("BEGIN")

                # ÎåÄÏö©Îüâ Î∞∞Ïπò Ï≤òÎ¶¨ (Ï≤≠ÌÅ¨ Îã®ÏúÑ)
                chunk_size = CollectorConfig.BATCH_SIZE
                total_chunks = (len(new_ips) + chunk_size - 1) // chunk_size

                for chunk_idx, chunk in enumerate(
                    self._get_batches(new_ips, chunk_size)
                ):
                    chunk_saved = self._optimized_batch_insert(cursor, chunk)
                    saved_count += chunk_saved

                    # ÏßÑÌñâ ÏÉÅÌô© Î°úÍπÖ
                    if chunk_idx % 10 == 0:
                        logger.info(f"üìà Ï≤òÎ¶¨ ÏßÑÌñâÎ•†: {chunk_idx+1}/{total_chunks} Ï≤≠ÌÅ¨ ÏôÑÎ£å")

                # Ïª§Î∞ã Ï†Ñ ÏµúÏ¢Ö Í≤ÄÏ¶ù
                cursor.execute(
                    "SELECT COUNT(*) FROM blacklist_ips WHERE created_at >= %s",
                    (datetime.now() - timedelta(minutes=5),),
                )
                recent_count = cursor.fetchone()[0]

                conn.commit()
                cursor.close()

                processing_time = time.time() - processing_start
                logger.info(
                    f"‚úÖ ÎåÄÏö©Îüâ Î∞∞Ïπò Ï≤òÎ¶¨ ÏôÑÎ£å: {saved_count}Í∞ú IP Ï†ÄÏû• ({processing_time:.2f}Ï¥à)"
                )

        except Exception as e:
            logger.error(f"‚ùå ÎåÄÏö©Îüâ Î∞∞Ïπò Ï≤òÎ¶¨ Ïã§Ìå®: {e}")

        return saved_count

    def _filter_invalid_ips(self, ip_data: List[Dict[str, Any]]) -> tuple[List[Dict[str, Any]], int]:
        """
        ÏÇ¨ÏÑ§ IP Î∞è Ïò§ÌÉê IP ÌïÑÌÑ∞ÎßÅ

        Ï†úÏô∏ ÎåÄÏÉÅ:
        - ÏÇ¨ÏÑ§ IP ÎåÄÏó≠ (10.0.0.0/8, 172.16.0.0/12, 192.168.0.0/16)
        - Loopback (127.0.0.0/8)
        - Link-local (169.254.0.0/16)
        - ÏûòÎ™ªÎêú IP ÌòïÏãù
        - Reserved IP
        """
        valid_ips = []
        excluded_count = 0

        for item in ip_data:
            ip_str = item.get("ip_address")
            if not ip_str:
                excluded_count += 1
                continue

            try:
                ip = ipaddress.ip_address(ip_str)

                # ÏÇ¨ÏÑ§ IP, Loopback, Link-local, Reserved Ï†úÏô∏
                if ip.is_private or ip.is_loopback or ip.is_link_local or ip.is_reserved:
                    excluded_count += 1
                    logger.debug(f"üö´ Ï†úÏô∏Îêú IP: {ip_str} (ÏÇ¨ÏÑ§/ÏòàÏïΩ ÎåÄÏó≠)")
                    continue

                # Ïú†Ìö®Ìïú Í≥µÏù∏ IP
                valid_ips.append(item)

            except ValueError:
                # ÏûòÎ™ªÎêú IP ÌòïÏãù
                excluded_count += 1
                logger.debug(f"üö´ Ï†úÏô∏Îêú IP: {ip_str} (ÏûòÎ™ªÎêú ÌòïÏãù)")
                continue

        logger.info(f"üìä IP ÌïÑÌÑ∞ÎßÅ: {len(valid_ips)}Í∞ú Ïú†Ìö®, {excluded_count}Í∞ú Ï†úÏô∏")
        return valid_ips, excluded_count

    def _memory_optimized_dedup(
        self, ip_data: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """Î©îÎ™®Î¶¨ ÏµúÏ†ÅÌôîÎêú Ï§ëÎ≥µ Ï†úÍ±∞ - ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞ ÏßÄÏõê"""
        seen_ips = set()
        unique_data = []

        # Î©îÎ™®Î¶¨ Ìö®Ïú®Ï†ÅÏù∏ Ï§ëÎ≥µ Ï†úÍ±∞
        for item in ip_data:
            ip_addr = item.get("ip_address")
            if ip_addr and ip_addr not in seen_ips:
                seen_ips.add(ip_addr)
                unique_data.append(item)

                # Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Ï†úÌïú
                if len(unique_data) >= self._cache_max_size:
                    logger.warning(f"‚ö†Ô∏è Î©îÎ™®Î¶¨ Ï†úÌïúÏóê ÎèÑÎã¨: {len(unique_data)}Í∞ú IPÎ°ú Ï†úÌïú")
                    break

        return unique_data

    def _batch_check_existing_ips(self, ip_addresses: List[str]) -> set:
        """Î∞∞ÏπòÎ°ú Í∏∞Ï°¥ IP Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏ - ÏÑ±Îä• ÏµúÏ†ÅÌôî"""
        if not ip_addresses:
            return set()

        existing_ips = set()

        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()

                # ÎåÄÏö©Îüâ IN Ï†à ÏµúÏ†ÅÌôî
                batch_size = 1000
                for batch in self._get_batches(ip_addresses, batch_size):
                    placeholders = ",".join(["%s"] * len(batch))
                    query = f"""
                        SELECT DISTINCT ip_address 
                        FROM blacklist_ips 
                        WHERE ip_address IN ({placeholders})
                    """
                    cursor.execute(query, batch)
                    results = cursor.fetchall()
                    existing_ips.update(row[0] for row in results)

                cursor.close()

        except Exception as e:
            logger.error(f"Í∏∞Ï°¥ IP ÌôïÏù∏ Ïã§Ìå®: {e}")

        return existing_ips

    def _get_batches(self, data: List[Any], batch_size: int):
        """Î©îÎ™®Î¶¨ Ìö®Ïú®Ï†ÅÏù∏ Î∞∞Ïπò Î∂ÑÌï†"""
        for i in range(0, len(data), batch_size):
            yield data[i : i + batch_size]

    def _optimized_batch_insert(self, cursor, batch: List[Dict[str, Any]]) -> int:
        """ÏµúÏ†ÅÌôîÎêú Î∞∞Ïπò ÏÇΩÏûÖ - ÏßÅÏ†ë executemany ÏÇ¨Ïö©"""
        if not batch:
            return 0

        # Î∞îÎ°ú fallback Î©îÏÑúÎìú ÏÇ¨Ïö© (COPYÎäî ON CONFLICT ÏßÄÏõê ÏïàÌï®)
        return self._fallback_batch_insert(cursor, batch)

    def _fallback_batch_insert(self, cursor, batch: List[Dict[str, Any]]) -> int:
        """ÎåÄÏ≤¥ Î∞∞Ïπò ÏÇΩÏûÖ Î∞©Ïãù - executemany (raw_data JSONB Ìè¨Ìï®)"""
        values = []
        for item in batch:
            # raw_dataÎ•º JSON Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò
            raw_data_value = item.get("raw_data")
            if raw_data_value and isinstance(raw_data_value, dict):
                raw_data_json = json.dumps(raw_data_value, ensure_ascii=False)
            elif isinstance(raw_data_value, str):
                raw_data_json = raw_data_value
            else:
                # raw_dataÍ∞Ä ÏóÜÏúºÎ©¥ ÏõêÎ≥∏ itemÏóêÏÑú Í¥ÄÎ†® Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂úÌïòÏó¨ Ï†ÄÏû•
                raw_data_json = json.dumps({
                    "ip_address": item.get("ip_address"),
                    "country": item.get("country"),
                    "reason": item.get("reason"),
                    "detection_date": str(item.get("detection_date")) if item.get("detection_date") else None,
                    "removal_date": str(item.get("removal_date")) if item.get("removal_date") else None,
                    "confidence_level": item.get("confidence_level"),
                    "collection_timestamp": datetime.now().isoformat(),
                }, ensure_ascii=False)

            values.append(
                (
                    item.get("ip_address"),
                    item.get("reason", "Blacklist IP"),
                    item.get("source", "COLLECTOR"),
                    self._convert_confidence_to_int(item.get("confidence_level", 50)),
                    item.get("detection_count", 1),
                    item.get("last_seen", datetime.now()),
                    item.get("is_active", True),
                    datetime.now(),
                    datetime.now(),
                    self._convert_date_string(item.get("detection_date")),
                    self._convert_date_string(item.get("removal_date")),
                    item.get("country"),
                    raw_data_json,  # raw_data JSONB Ï∂îÍ∞Ä
                )
            )

        try:
            cursor.executemany(
                """
                INSERT INTO blacklist_ips
                (ip_address, reason, source, confidence_level,
                 detection_count, last_seen, is_active, created_at, updated_at,
                 detection_date, removal_date, country, raw_data)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (ip_address, source) DO UPDATE SET
                    detection_count = blacklist_ips.detection_count + 1,
                    last_seen = EXCLUDED.last_seen,
                    updated_at = EXCLUDED.updated_at,
                    reason = EXCLUDED.reason,
                    country = COALESCE(EXCLUDED.country, blacklist_ips.country),
                    raw_data = EXCLUDED.raw_data
            """,
                values,
            )
            return cursor.rowcount
        except Exception as e:
            logger.error(f"Î∞∞Ïπò ÏÇΩÏûÖ Ïã§Ìå®: {e}")
            return 0

    def _convert_confidence_to_int(self, confidence_value) -> int:
        """Ïã†Î¢∞ÎèÑ Í∞íÏùÑ Ï†ïÏàòÎ°ú Î≥ÄÌôò"""
        if isinstance(confidence_value, int):
            return confidence_value
        elif isinstance(confidence_value, str):
            confidence_mapping = {
                "high": 90,
                "medium": 50,
                "low": 10,
                "critical": 95,
                "unknown": 5,
            }
            return confidence_mapping.get(confidence_value.lower(), 50)
        return 50

    def _convert_date_string(self, date_str):
        """ÎÇ†Ïßú Î¨∏ÏûêÏó¥ÏùÑ date Í∞ùÏ≤¥Î°ú Î≥ÄÌôò"""
        if not date_str or not isinstance(date_str, str):
            return None

        try:
            return datetime.strptime(date_str, "%Y-%m-%d").date()
        except Exception:
            return None

    def record_collection_history(
        self,
        source: str,
        success: bool,
        items_collected: int,
        execution_time_ms: int,
        error_message: str = None,
    ):
        """ÏàòÏßë ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    """
                    INSERT INTO collection_history
                    (service_name, success, items_collected, execution_time_ms, 
                     error_message, collection_date)
                    VALUES (%s, %s, %s, %s, %s, %s)
                """,
                    (
                        source.lower(),
                        success,
                        items_collected,
                        execution_time_ms,
                        error_message,
                        datetime.now(),
                    ),
                )
                conn.commit()
                cursor.close()
        except Exception as e:
            logger.error(f"ÏàòÏßë ÌûàÏä§ÌÜ†Î¶¨ Í∏∞Î°ù Ïã§Ìå®: {e}")

    def get_total_ip_count(self) -> int:
        """Ï†ÑÏ≤¥ IP Í∞úÏàò Î∞òÌôò - ÏµúÏ¥à ÏàòÏßë Ïó¨Î∂Ä ÌôïÏù∏Ïö©"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT COUNT(*) FROM blacklist_ips")
                result = cursor.fetchone()
                cursor.close()
                return result[0] if result else 0
        except Exception as e:
            logger.error(f"Ï¥ù IP Í∞úÏàò Ï°∞Ìöå Ïã§Ìå®: {e}")
            return 0

    def get_collection_stats(self) -> Dict[str, Any]:
        """Í≥†ÏÑ±Îä• ÏàòÏßë ÌÜµÍ≥Ñ Ï°∞Ìöå"""
        try:
            with self.get_connection() as conn:
                cursor = conn.cursor()

                # Î≥ëÎ†¨ ÌÜµÍ≥Ñ ÏøºÎ¶¨ ÏµúÏ†ÅÌôî
                cursor.execute(
                    """
                    WITH stats AS (
                        SELECT 
                            COUNT(*) as total_ips,
                            COUNT(*) FILTER (WHERE is_active = true) as active_ips,
                            MAX(created_at) as latest_collection
                        FROM blacklist_ips
                    ),
                    source_stats AS (
                        SELECT json_object_agg(source, cnt) as source_breakdown
                        FROM (
                            SELECT source, COUNT(*) as cnt 
                            FROM blacklist_ips 
                            GROUP BY source
                        ) s
                    )
                    SELECT s.total_ips, s.active_ips, s.latest_collection, 
                           ss.source_breakdown
                    FROM stats s CROSS JOIN source_stats ss
                """
                )

                result = cursor.fetchone()
                cursor.close()

                if result:
                    return {
                        "total_ips": result[0],
                        "active_ips": result[1],
                        "latest_collection": result[2],
                        "source_breakdown": result[3] or {},
                        "cache_size": len(self._ip_cache),
                        "performance_mode": "optimized",
                    }

        except Exception as e:
            logger.error(f"ÌÜµÍ≥Ñ Ï°∞Ìöå Ïã§Ìå®: {e}")

        return {}


# Ï†ÑÏó≠ Ïù∏Ïä§ÌÑ¥Ïä§
db_service = DatabaseService()
