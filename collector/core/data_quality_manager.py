"""
ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ ì‹œìŠ¤í…œ
ê¸°ì¡´ ë°ì´í„° ìœ ì§€ ë° í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ í†µí•© ê´€ë¦¬
"""

import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from core.database import db_service

logger = logging.getLogger(__name__)


class DataQualityManager:
    """ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ì"""

    def __init__(self):
        self.quality_metrics = {
            "total_ips": 0,
            "active_ips": 0,
            "inactive_ips": 0,
            "duplicate_ips": 0,
            "invalid_ips": 0,
            "missing_dates": 0,
            "data_freshness_score": 0,
            "last_quality_check": None,
        }

        self.quality_thresholds = {
            "max_age_days": 90,  # ìµœëŒ€ ë°ì´í„° ë³´ì¡´ ê¸°ê°„
            "min_freshness_score": 70,  # ìµœì†Œ ì‹ ì„ ë„ ì ìˆ˜
            "max_duplicate_rate": 0.05,  # ìµœëŒ€ ì¤‘ë³µë¥  5%
            "min_active_rate": 0.80,  # ìµœì†Œ í™œì„±ë¥  80%
        }

    def perform_comprehensive_quality_check(self) -> Dict[str, Any]:
        """í¬ê´„ì  ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬"""
        logger.info("ğŸ” í¬ê´„ì  ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ì‹œì‘")

        quality_report = {
            "check_timestamp": datetime.now().isoformat(),
            "metrics": {},
            "issues": [],
            "recommendations": [],
            "actions_taken": [],
        }

        try:
            # 1. ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘
            basic_stats = self._collect_basic_statistics()
            quality_report["metrics"].update(basic_stats)

            # 2. ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬
            integrity_issues = self._check_data_integrity()
            quality_report["issues"].extend(integrity_issues)

            # 3. ë°ì´í„° ì‹ ì„ ë„ ë¶„ì„
            freshness_analysis = self._analyze_data_freshness()
            quality_report["metrics"].update(freshness_analysis)

            # 4. ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬
            duplicate_analysis = self._detect_duplicates()
            quality_report["metrics"].update(duplicate_analysis)

            # 5. ìë™ ì •ì œ ìˆ˜í–‰
            cleanup_actions = self._perform_automatic_cleanup()
            quality_report["actions_taken"].extend(cleanup_actions)

            # 6. ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self._generate_recommendations(quality_report)
            quality_report["recommendations"] = recommendations

            # 7. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self._calculate_quality_score(quality_report)
            quality_report["overall_quality_score"] = quality_score

            logger.info(f"âœ… ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ì™„ë£Œ (ì ìˆ˜: {quality_score}/100)")

            # í’ˆì§ˆ ë³´ê³ ì„œ ì €ì¥
            self._save_quality_report(quality_report)

            return quality_report

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {e}")
            quality_report["error"] = str(e)
            return quality_report

    def _collect_basic_statistics(self) -> Dict[str, Any]:
        """ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘"""
        try:
            conn = db_service.get_connection()
            cursor = conn.cursor()

            # ì „ì²´ IP í†µê³„
            cursor.execute(
                """
                SELECT 
                    COUNT(*) as total_ips,
                    COUNT(*) FILTER (WHERE is_active = true) as active_ips,
                    COUNT(*) FILTER (WHERE is_active = false) as inactive_ips,
                    COUNT(*) FILTER (WHERE detection_date IS NULL) as missing_detection_date,
                    COUNT(*) FILTER (WHERE removal_date IS NULL) as missing_removal_date,
                    COUNT(DISTINCT ip_address) as unique_ips,
                    COUNT(*) - COUNT(DISTINCT ip_address) as duplicate_count
                FROM blacklist_ips
            """
            )

            stats = cursor.fetchone()

            cursor.close()
            db_service.return_connection(conn)

            return {
                "total_ips": stats[0],
                "active_ips": stats[1],
                "inactive_ips": stats[2],
                "missing_detection_date": stats[3],
                "missing_removal_date": stats[4],
                "unique_ips": stats[5],
                "duplicate_ips": stats[6],
                "active_rate": round(stats[1] / stats[0] * 100, 2)
                if stats[0] > 0
                else 0,
                "duplicate_rate": round(stats[6] / stats[0] * 100, 2)
                if stats[0] > 0
                else 0,
            }

        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}

    def _check_data_integrity(self) -> List[str]:
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬"""
        issues = []

        try:
            conn = db_service.get_connection()
            cursor = conn.cursor()

            # 1. ì˜ëª»ëœ IP ì£¼ì†Œ í˜•ì‹ ê²€ì‚¬
            cursor.execute(
                """
                SELECT COUNT(*) FROM blacklist_ips 
                WHERE ip_address !~ '^([0-9]{1,3}\.){3}[0-9]{1,3}$'
                AND ip_address !~ '^([0-9a-fA-F]{0,4}:){1,7}[0-9a-fA-F]{0,4}$'
            """
            )
            invalid_ips = cursor.fetchone()[0]

            if invalid_ips > 0:
                issues.append(f"ì˜ëª»ëœ IP ì£¼ì†Œ í˜•ì‹: {invalid_ips}ê°œ")

            # 2. ë…¼ë¦¬ì  ëª¨ìˆœ ê²€ì‚¬ (removal_date < detection_date)
            cursor.execute(
                """
                SELECT COUNT(*) FROM blacklist_ips 
                WHERE detection_date IS NOT NULL 
                AND removal_date IS NOT NULL 
                AND removal_date < detection_date
            """
            )
            logical_errors = cursor.fetchone()[0]

            if logical_errors > 0:
                issues.append(f"ë…¼ë¦¬ì  ëª¨ìˆœ (í•´ì œì¼ < íƒì§€ì¼): {logical_errors}ê°œ")

            # 3. ë§Œë£Œëœ IPê°€ ì—¬ì „íˆ í™œì„± ìƒíƒœì¸ ê²½ìš°
            cursor.execute(
                """
                SELECT COUNT(*) FROM blacklist_ips 
                WHERE is_active = true 
                AND removal_date IS NOT NULL 
                AND removal_date <= CURRENT_DATE
            """
            )
            expired_active = cursor.fetchone()[0]

            if expired_active > 0:
                issues.append(f"ë§Œë£Œë˜ì—ˆì§€ë§Œ í™œì„± ìƒíƒœì¸ IP: {expired_active}ê°œ")

            cursor.close()
            db_service.return_connection(conn)

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            issues.append(f"ë¬´ê²°ì„± ê²€ì‚¬ ì˜¤ë¥˜: {e}")

        return issues

    def _analyze_data_freshness(self) -> Dict[str, Any]:
        """ë°ì´í„° ì‹ ì„ ë„ ë¶„ì„"""
        try:
            conn = db_service.get_connection()
            cursor = conn.cursor()

            # ìµœì‹  ë°ì´í„° ë¶„í¬ ë¶„ì„
            cursor.execute(
                """
                SELECT 
                    COUNT(*) FILTER (WHERE created_at >= CURRENT_DATE - INTERVAL '7 days') as last_7_days,
                    COUNT(*) FILTER (WHERE created_at >= CURRENT_DATE - INTERVAL '30 days') as last_30_days,
                    COUNT(*) FILTER (WHERE created_at >= CURRENT_DATE - INTERVAL '90 days') as last_90_days,
                    COUNT(*) as total,
                    MAX(created_at) as latest_data,
                    MIN(created_at) as oldest_data
                FROM blacklist_ips
            """
            )

            freshness_data = cursor.fetchone()

            cursor.close()
            db_service.return_connection(conn)

            # ì‹ ì„ ë„ ì ìˆ˜ ê³„ì‚° (ìµœê·¼ 30ì¼ ë°ì´í„° ë¹„ìœ¨ ê¸°ì¤€)
            freshness_score = 0
            if freshness_data[3] > 0:  # total > 0
                recent_ratio = (
                    freshness_data[1] / freshness_data[3]
                )  # last_30_days / total
                freshness_score = min(100, recent_ratio * 100 * 2)  # ìµœëŒ€ 100ì 

            return {
                "data_last_7_days": freshness_data[0],
                "data_last_30_days": freshness_data[1],
                "data_last_90_days": freshness_data[2],
                "freshness_score": round(freshness_score, 2),
                "latest_data_date": freshness_data[4].isoformat()
                if freshness_data[4]
                else None,
                "oldest_data_date": freshness_data[5].isoformat()
                if freshness_data[5]
                else None,
            }

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì‹ ì„ ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"freshness_score": 0}

    def _detect_duplicates(self) -> Dict[str, Any]:
        """ì¤‘ë³µ ë°ì´í„° ê²€ì¶œ"""
        try:
            conn = db_service.get_connection()
            cursor = conn.cursor()

            # ì¤‘ë³µ IP ê²€ì¶œ
            cursor.execute(
                """
                SELECT 
                    ip_address, 
                    source, 
                    COUNT(*) as duplicate_count
                FROM blacklist_ips 
                GROUP BY ip_address, source 
                HAVING COUNT(*) > 1
                ORDER BY duplicate_count DESC
                LIMIT 10
            """
            )

            duplicate_groups = cursor.fetchall()

            # ì „ì²´ ì¤‘ë³µ í†µê³„
            cursor.execute(
                """
                SELECT 
                    COUNT(*) - COUNT(DISTINCT ip_address, source) as total_duplicates,
                    COUNT(DISTINCT ip_address, source) as unique_combinations,
                    COUNT(*) as total_records
                FROM blacklist_ips
            """
            )

            duplicate_stats = cursor.fetchone()

            cursor.close()
            db_service.return_connection(conn)

            return {
                "total_duplicates": duplicate_stats[0],
                "unique_combinations": duplicate_stats[1],
                "duplicate_groups": duplicate_groups,
                "duplicate_percentage": round(
                    duplicate_stats[0] / duplicate_stats[2] * 100, 2
                )
                if duplicate_stats[2] > 0
                else 0,
            }

        except Exception as e:
            logger.error(f"âŒ ì¤‘ë³µ ë°ì´í„° ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return {"total_duplicates": 0}

    def _perform_automatic_cleanup(self) -> List[str]:
        """ìë™ ë°ì´í„° ì •ì œ"""
        actions = []

        try:
            conn = db_service.get_connection()
            cursor = conn.cursor()

            # 1. ë§Œë£Œëœ IP ë¹„í™œì„±í™”
            cursor.execute(
                """
                UPDATE blacklist_ips 
                SET is_active = false 
                WHERE is_active = true 
                AND removal_date IS NOT NULL 
                AND removal_date <= CURRENT_DATE
            """
            )
            expired_deactivated = cursor.rowcount
            if expired_deactivated > 0:
                actions.append(f"ë§Œë£Œëœ IP {expired_deactivated}ê°œ ë¹„í™œì„±í™”")

            # 2. ì˜¤ë˜ëœ ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼ ì´ìƒ)
            cursor.execute(
                """
                DELETE FROM blacklist_ips 
                WHERE is_active = false 
                AND (removal_date IS NULL OR removal_date < CURRENT_DATE - INTERVAL '90 days')
                AND created_at < CURRENT_DATE - INTERVAL '90 days'
            """
            )
            old_deleted = cursor.rowcount
            if old_deleted > 0:
                actions.append(f"ì˜¤ë˜ëœ ë¹„í™œì„± ë°ì´í„° {old_deleted}ê°œ ì •ë¦¬")

            # 3. ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ (ìµœì‹  ë°ì´í„° ìœ ì§€)
            cursor.execute(
                """
                DELETE FROM blacklist_ips 
                WHERE id NOT IN (
                    SELECT DISTINCT ON (ip_address, source) id 
                    FROM blacklist_ips 
                    ORDER BY ip_address, source, created_at DESC
                )
            """
            )
            duplicates_removed = cursor.rowcount
            if duplicates_removed > 0:
                actions.append(f"ì¤‘ë³µ ë°ì´í„° {duplicates_removed}ê°œ ì •ë¦¬")

            conn.commit()
            cursor.close()
            db_service.return_connection(conn)

        except Exception as e:
            logger.error(f"âŒ ìë™ ì •ì œ ì‹¤íŒ¨: {e}")
            actions.append(f"ìë™ ì •ì œ ì˜¤ë¥˜: {e}")

        return actions

    def _generate_recommendations(self, quality_report: Dict) -> List[str]:
        """í’ˆì§ˆ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        metrics = quality_report.get("metrics", {})

        # í™œì„±ë¥  ì²´í¬
        if (
            metrics.get("active_rate", 0)
            < self.quality_thresholds["min_active_rate"] * 100
        ):
            recommendations.append("í™œì„± IP ë¹„ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘ ë¹ˆë„ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")

        # ì‹ ì„ ë„ ì²´í¬
        if (
            metrics.get("freshness_score", 0)
            < self.quality_thresholds["min_freshness_score"]
        ):
            recommendations.append("ë°ì´í„° ì‹ ì„ ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ìµœê·¼ ë°ì´í„° ìˆ˜ì§‘ì„ ê°•í™”í•˜ì„¸ìš”.")

        # ì¤‘ë³µë¥  ì²´í¬
        if (
            metrics.get("duplicate_rate", 0)
            > self.quality_thresholds["max_duplicate_rate"] * 100
        ):
            recommendations.append("ì¤‘ë³µ ë°ì´í„° ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. ì •ê¸°ì ì¸ ì¤‘ë³µ ì œê±°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

        # ëˆ„ë½ í•„ë“œ ì²´í¬
        if metrics.get("missing_detection_date", 0) > 0:
            recommendations.append("íƒì§€ì¼ì´ ëˆ„ë½ëœ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ë¥¼ ì ê²€í•˜ì„¸ìš”.")

        return recommendations

    def _calculate_quality_score(self, quality_report: Dict) -> int:
        """ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        metrics = quality_report.get("metrics", {})

        # ê° ì§€í‘œë³„ ì ìˆ˜ ê³„ì‚° (0-100)
        active_score = min(100, metrics.get("active_rate", 0))
        freshness_score = metrics.get("freshness_score", 0)
        duplicate_score = max(
            0, 100 - metrics.get("duplicate_rate", 0) * 20
        )  # ì¤‘ë³µë¥ ì´ ë†’ì„ìˆ˜ë¡ ê°ì 
        integrity_score = max(
            0, 100 - len(quality_report.get("issues", [])) * 10
        )  # ì´ìŠˆ ë‹¹ 10ì  ê°ì 

        # ê°€ì¤‘ í‰ê·  (í™œì„±ë¥  30%, ì‹ ì„ ë„ 30%, ì¤‘ë³µë¥  20%, ë¬´ê²°ì„± 20%)
        overall_score = (
            active_score * 0.3
            + freshness_score * 0.3
            + duplicate_score * 0.2
            + integrity_score * 0.2
        )

        return int(overall_score)

    def _save_quality_report(self, quality_report: Dict):
        """í’ˆì§ˆ ë³´ê³ ì„œ ì €ì¥"""
        try:
            # í’ˆì§ˆ ë³´ê³ ì„œë¥¼ ë¡œê·¸ì— ìš”ì•½ ê¸°ë¡
            logger.info(f"ğŸ“Š í’ˆì§ˆ ë³´ê³ ì„œ ìš”ì•½:")
            logger.info(
                f"  - ì „ì²´ ì ìˆ˜: {quality_report.get('overall_quality_score', 0)}/100"
            )
            logger.info(
                f"  - ì´ IP: {quality_report.get('metrics', {}).get('total_ips', 0)}ê°œ"
            )
            logger.info(
                f"  - í™œì„± IP: {quality_report.get('metrics', {}).get('active_ips', 0)}ê°œ"
            )
            logger.info(
                f"  - ì‹ ì„ ë„: {quality_report.get('metrics', {}).get('freshness_score', 0)}"
            )
            logger.info(f"  - ì´ìŠˆ: {len(quality_report.get('issues', []))}ê°œ")
            logger.info(f"  - ê¶Œì¥ì‚¬í•­: {len(quality_report.get('recommendations', []))}ê°œ")

        except Exception as e:
            logger.error(f"âŒ í’ˆì§ˆ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")

    def maintain_data_retention_policy(self):
        """ë°ì´í„° ë³´ì¡´ ì •ì±… ìœ ì§€"""
        logger.info("ğŸ—‚ï¸ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš© ì‹œì‘")

        try:
            conn = db_service.get_connection()
            cursor = conn.cursor()

            # 50,000ê°œ IP ë°ì´í„° ë³´ì¡´ (ìµœì‹ ìˆœ)
            cursor.execute(
                """
                DELETE FROM blacklist_ips 
                WHERE id NOT IN (
                    SELECT id FROM blacklist_ips 
                    ORDER BY created_at DESC, id DESC 
                    LIMIT 1000000
                )
            """
            )

            deleted_count = cursor.rowcount
            conn.commit()

            cursor.close()
            db_service.return_connection(conn)

            if deleted_count > 0:
                logger.info(f"ğŸ“¦ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš©: {deleted_count}ê°œ ì˜¤ë˜ëœ ë ˆì½”ë“œ ì‚­ì œ")
            else:
                logger.info("ğŸ“¦ ë°ì´í„° ë³´ì¡´ ì •ì±…: ì‚­ì œí•  ë°ì´í„° ì—†ìŒ")

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš© ì‹¤íŒ¨: {e}")


# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
data_quality_manager = DataQualityManager()
