"""
Multi-Source Threat Intelligence Collector
ë‹¤ì¤‘ ì†ŒìŠ¤ ìœ„í˜‘ ì •ë³´ ìˆ˜ì§‘ê¸° - ë„“ì€ ë²”ìœ„ ìˆ˜ì§‘ì„ ìœ„í•œ í†µí•© ì‹œìŠ¤í…œ
"""

import logging
import asyncio
import concurrent.futures
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Set
from dataclasses import dataclass
from enum import Enum
import time
import json

from collector.core.regtech_collector import regtech_collector
from collector.config import CollectorConfig

logger = logging.getLogger(__name__)


class SourceType(Enum):
    """ìœ„í˜‘ ì •ë³´ ì†ŒìŠ¤ íƒ€ì…"""

    REGTECH = "regtech"  # í•œêµ­ ê¸ˆìœµë³´ì•ˆì›
    ABUSE_CH = "abuse_ch"  # Abuse.ch ìœ„í˜‘ í”¼ë“œ
    MALWARE_BAZAAR = "malware_bazaar"  # Malware Bazaar
    URLHAUS = "urlhaus"  # URLhaus
    PHISHTANK = "phishtank"  # PhishTank
    OPENPHISH = "openphish"  # OpenPhish
    VIRUSTOTAL = "virustotal"  # VirusTotal
    ALIENVAULT = "alienvault"  # AlienVault OTX
    THREATFOX = "threatfox"  # ThreatFox
    FEODO = "feodo"  # Feodo Tracker
    CUSTOM_API = "custom_api"  # ì‚¬ìš©ì ì •ì˜ API
    RSS_FEED = "rss_feed"  # RSS í”¼ë“œ
    CSV_FILE = "csv_file"  # CSV íŒŒì¼
    JSON_API = "json_api"  # JSON API


@dataclass
class SourceConfig:
    """ì†ŒìŠ¤ ì„¤ì •"""

    source_type: SourceType
    name: str
    url: str
    api_key: Optional[str] = None
    headers: Optional[Dict[str, str]] = None
    params: Optional[Dict[str, Any]] = None
    enabled: bool = True
    priority: int = 1  # 1=ìµœê³ , 5=ìµœì €
    rate_limit: float = 1.0  # ì´ˆë‹¹ ìš”ì²­ ìˆ˜
    timeout: int = 30
    retry_count: int = 3
    data_format: str = "json"  # json, xml, csv, text
    ip_field: str = "ip"
    date_field: Optional[str] = None
    reason_field: Optional[str] = None
    confidence_boost: int = 0  # ì‹ ë¢°ë„ ì¶”ê°€ì 
    category: str = "malicious"


class MultiSourceCollector:
    """ë‹¤ì¤‘ ì†ŒìŠ¤ ìœ„í˜‘ ì •ë³´ ìˆ˜ì§‘ê¸°"""

    def __init__(self):
        self.sources: Dict[str, SourceConfig] = {}
        self.collection_stats = {
            "total_sources": 0,
            "active_sources": 0,
            "total_collected": 0,
            "collection_history": [],
        }
        self._setup_default_sources()

    def _setup_default_sources(self):
        """ê¸°ë³¸ ìœ„í˜‘ ì •ë³´ ì†ŒìŠ¤ ì„¤ì •"""

        # 1. ê¸°ì¡´ REGTECH (ìµœê³  ìš°ì„ ìˆœìœ„)
        self.add_source(
            SourceConfig(
                source_type=SourceType.REGTECH,
                name="í•œêµ­ ê¸ˆìœµë³´ì•ˆì› REGTECH",
                url="https://regtech.fsec.or.kr",
                priority=1,
                rate_limit=0.5,
                confidence_boost=20,
            )
        )

        # 2. Abuse.ch URLhaus (URL ê¸°ë°˜ ìœ„í˜‘)
        self.add_source(
            SourceConfig(
                source_type=SourceType.URLHAUS,
                name="URLhaus Malware URLs",
                url="https://urlhaus-api.abuse.ch/v1/payloads/recent/",
                priority=2,
                rate_limit=2.0,
                data_format="json",
                ip_field="url_host",
                confidence_boost=15,
            )
        )

        # 3. ThreatFox IOCs
        self.add_source(
            SourceConfig(
                source_type=SourceType.THREATFOX,
                name="ThreatFox IOCs",
                url="https://threatfox-api.abuse.ch/api/v1/",
                priority=2,
                rate_limit=2.0,
                data_format="json",
                ip_field="ioc",
                confidence_boost=15,
            )
        )

        # 4. Feodo Tracker (ë´‡ë„· C&C)
        self.add_source(
            SourceConfig(
                source_type=SourceType.FEODO,
                name="Feodo Tracker Botnet C&C",
                url="https://feodotracker.abuse.ch/downloads/ipblocklist_recommended.txt",
                priority=2,
                rate_limit=1.0,
                data_format="text",
                confidence_boost=18,
                category="botnet",
            )
        )

        # 5. PhishTank (í”¼ì‹±)
        self.add_source(
            SourceConfig(
                source_type=SourceType.PHISHTANK,
                name="PhishTank Phishing URLs",
                url="http://data.phishtank.com/data/online-valid.json",
                priority=3,
                rate_limit=0.2,  # ì œí•œì 
                data_format="json",
                ip_field="url",
                confidence_boost=10,
                category="phishing",
            )
        )

        # 6. OpenPhish
        self.add_source(
            SourceConfig(
                source_type=SourceType.OPENPHISH,
                name="OpenPhish Feed",
                url="https://openphish.com/feed.txt",
                priority=3,
                rate_limit=1.0,
                data_format="text",
                confidence_boost=8,
                category="phishing",
            )
        )

        # 7. Custom API ì˜ˆì‹œ (ì‚¬ìš©ì í™•ì¥ ê°€ëŠ¥)
        self.add_source(
            SourceConfig(
                source_type=SourceType.CUSTOM_API,
                name="Custom Threat Feed",
                url="https://example.com/threat-feed",
                priority=4,
                enabled=False,  # ê¸°ë³¸ ë¹„í™œì„±í™”
                rate_limit=1.0,
                headers={"X-API-Key": "YOUR_API_KEY"},
                confidence_boost=5,
            )
        )

        logger.info(f"ğŸ“‹ ê¸°ë³¸ ìœ„í˜‘ ì •ë³´ ì†ŒìŠ¤ {len(self.sources)}ê°œ ì„¤ì • ì™„ë£Œ")

    def add_source(self, source_config: SourceConfig):
        """ìƒˆ ì†ŒìŠ¤ ì¶”ê°€"""
        source_id = (
            f"{source_config.source_type.value}_{source_config.name.replace(' ', '_')}"
        )
        self.sources[source_id] = source_config

        if source_config.enabled:
            self.collection_stats["active_sources"] += 1
        self.collection_stats["total_sources"] += 1

        logger.info(
            f"â• ìœ„í˜‘ ì •ë³´ ì†ŒìŠ¤ ì¶”ê°€: {source_config.name} ({source_config.source_type.value})"
        )

    async def collect_from_all_sources(
        self,
        max_ips_per_source: int = 50000,
        parallel_sources: int = 5,
        date_range_days: int = 7,
    ) -> Dict[str, Any]:
        """ëª¨ë“  í™œì„±í™”ëœ ì†ŒìŠ¤ì—ì„œ ë³‘ë ¬ ìˆ˜ì§‘"""

        collection_start = time.time()
        logger.info(f"ğŸš€ ë‹¤ì¤‘ ì†ŒìŠ¤ ë„“ì€ ë²”ìœ„ ìˆ˜ì§‘ ì‹œì‘")
        logger.info(f"ğŸ“Š ì„¤ì •: ì†ŒìŠ¤ë‹¹ ìµœëŒ€ {max_ips_per_source:,}ê°œ, ë³‘ë ¬ {parallel_sources}ê°œ")

        # í™œì„±í™”ëœ ì†ŒìŠ¤ í•„í„°ë§ ë° ìš°ì„ ìˆœìœ„ ì •ë ¬
        active_sources = [
            (source_id, config)
            for source_id, config in self.sources.items()
            if config.enabled
        ]
        active_sources.sort(key=lambda x: x[1].priority)

        collected_results = {}
        total_collected = 0

        # ë³‘ë ¬ ìˆ˜ì§‘ ì‹¤í–‰
        semaphore = asyncio.Semaphore(parallel_sources)

        async def collect_from_source(source_id: str, config: SourceConfig):
            async with semaphore:
                try:
                    logger.info(f"ğŸ”„ ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹œì‘: {config.name}")

                    if config.source_type == SourceType.REGTECH:
                        # ê¸°ì¡´ REGTECH ìˆ˜ì§‘ê¸° ì‚¬ìš©
                        result = await self._collect_regtech_async(
                            max_ips_per_source, date_range_days
                        )
                    else:
                        # ìƒˆë¡œìš´ ì†ŒìŠ¤ ìˆ˜ì§‘
                        result = await self._collect_from_external_source(
                            source_id, config, max_ips_per_source
                        )

                    collected_results[source_id] = result
                    logger.info(f"âœ… {config.name}: {len(result.get('data', []))}ê°œ ìˆ˜ì§‘")

                    return result

                except Exception as e:
                    logger.error(f"âŒ {config.name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    collected_results[source_id] = {
                        "success": False,
                        "error": str(e),
                        "data": [],
                    }
                    return {"success": False, "error": str(e), "data": []}

        # ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ë³‘ë ¬ ìˆ˜ì§‘
        tasks = [
            collect_from_source(source_id, config)
            for source_id, config in active_sources
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
        all_collected_data = []
        source_stats = {}

        for (source_id, config), result in zip(active_sources, results):
            if isinstance(result, Exception):
                logger.error(f"âŒ {config.name} ìˆ˜ì§‘ ì˜ˆì™¸: {result}")
                source_stats[source_id] = {"collected": 0, "error": str(result)}
                continue

            if isinstance(result, dict) and result.get("success"):
                source_data = result.get("data", [])
                all_collected_data.extend(source_data)
                source_stats[source_id] = {
                    "collected": len(source_data),
                    "source_name": config.name,
                    "confidence_boost": config.confidence_boost,
                }
            else:
                error_msg = (
                    result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                    if isinstance(result, dict)
                    else str(result)
                )
                source_stats[source_id] = {"collected": 0, "error": error_msg}

        # ì¤‘ë³µ ì œê±° ë° ë°ì´í„° í’ˆì§ˆ í–¥ìƒ
        unique_data = self._deduplicate_and_enhance(all_collected_data)
        total_collected = len(unique_data)

        collection_time = time.time() - collection_start

        # ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        collection_result = {
            "success": True,
            "total_collected": total_collected,
            "unique_ips": len(set(item.get("ip_address") for item in unique_data)),
            "sources_attempted": len(active_sources),
            "sources_successful": len(
                [s for s in source_stats.values() if "error" not in s]
            ),
            "collection_time_seconds": round(collection_time, 2),
            "source_breakdown": source_stats,
            "data": unique_data,
            "timestamp": datetime.now().isoformat(),
        }

        # ìˆ˜ì§‘ ì´ë ¥ ì—…ë°ì´íŠ¸
        self.collection_stats["total_collected"] += total_collected
        self.collection_stats["collection_history"].append(
            {
                "timestamp": datetime.now().isoformat(),
                "total_collected": total_collected,
                "sources_used": len(active_sources),
                "collection_time": collection_time,
            }
        )

        logger.info(f"ğŸ¯ ë‹¤ì¤‘ ì†ŒìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {total_collected:,}ê°œ IP, {collection_time:.2f}ì´ˆ")
        return collection_result

    async def _collect_regtech_async(
        self, max_ips: int, date_range_days: int
    ) -> Dict[str, Any]:
        """REGTECH ë¹„ë™ê¸° ìˆ˜ì§‘"""
        loop = asyncio.get_event_loop()

        def sync_collect():
            try:
                # ê¸°ì¡´ ì¸ì¦ í™•ì¸
                if not regtech_collector.authenticated:
                    username = CollectorConfig.REGTECH_ID
                    password = CollectorConfig.REGTECH_PW
                    if not regtech_collector.authenticate(username, password):
                        return {"success": False, "error": "REGTECH ì¸ì¦ ì‹¤íŒ¨", "data": []}

                # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
                end_date = datetime.now().strftime("%Y-%m-%d")
                start_date = (
                    datetime.now() - timedelta(days=date_range_days)
                ).strftime("%Y-%m-%d")

                # ë°ì´í„° ìˆ˜ì§‘
                collected_data = regtech_collector.collect_blacklist_data(
                    page_size=2000,
                    start_date=start_date,
                    end_date=end_date,
                    max_pages=max_ips // 2000 + 1,
                )

                # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
                if len(collected_data) > max_ips:
                    collected_data = collected_data[:max_ips]

                return {
                    "success": True,
                    "data": collected_data,
                    "source": "REGTECH",
                    "collection_params": {
                        "start_date": start_date,
                        "end_date": end_date,
                        "max_pages": max_ips // 2000 + 1,
                    },
                }

            except Exception as e:
                return {"success": False, "error": str(e), "data": []}

        return await loop.run_in_executor(None, sync_collect)

    async def _collect_from_external_source(
        self, source_id: str, config: SourceConfig, max_ips: int
    ) -> Dict[str, Any]:
        """ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        import aiohttp

        try:
            # Rate limiting
            await asyncio.sleep(1.0 / config.rate_limit)

            headers = config.headers or {}
            params = config.params or {}

            timeout = aiohttp.ClientTimeout(total=config.timeout)

            async with aiohttp.ClientSession(timeout=timeout) as session:
                if config.source_type == SourceType.THREATFOX:
                    # ThreatFox API íŠ¹ë³„ ì²˜ë¦¬
                    post_data = {"query": "get_iocs", "days": 7}
                    async with session.post(
                        config.url, json=post_data, headers=headers
                    ) as response:
                        data = await response.json()
                        return self._parse_threatfox_data(data, config, max_ips)

                elif config.data_format == "text":
                    # í…ìŠ¤íŠ¸ ê¸°ë°˜ í”¼ë“œ (Feodo, OpenPhish ë“±)
                    async with session.get(
                        config.url, headers=headers, params=params
                    ) as response:
                        text_data = await response.text()
                        return self._parse_text_feed(text_data, config, max_ips)

                elif config.data_format == "json":
                    # JSON ê¸°ë°˜ í”¼ë“œ
                    async with session.get(
                        config.url, headers=headers, params=params
                    ) as response:
                        json_data = await response.json()
                        return self._parse_json_feed(json_data, config, max_ips)

                else:
                    return {
                        "success": False,
                        "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í˜•ì‹: {config.data_format}",
                        "data": [],
                    }

        except Exception as e:
            logger.error(f"âŒ {config.name} ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {"success": False, "error": str(e), "data": []}

    def _parse_threatfox_data(
        self, data: Dict, config: SourceConfig, max_ips: int
    ) -> Dict[str, Any]:
        """ThreatFox ë°ì´í„° íŒŒì‹±"""
        collected_ips = []

        try:
            if data.get("query_status") == "ok":
                iocs = data.get("data", [])

                for ioc_data in iocs[:max_ips]:
                    ioc_value = ioc_data.get("ioc")
                    ioc_type = ioc_data.get("ioc_type", "")

                    # IP ì£¼ì†Œë§Œ í•„í„°ë§
                    if ioc_type in ["ip:port", "ip"] and self._is_valid_ip(
                        ioc_value.split(":")[0]
                    ):
                        ip_address = ioc_value.split(":")[0]

                        collected_ips.append(
                            {
                                "ip_address": ip_address,
                                "source": config.name,
                                "reason": ioc_data.get("threat_type", "ThreatFox IOC"),
                                "category": self._determine_category_from_threat_type(
                                    ioc_data.get("threat_type", "")
                                ),
                                "confidence_level": 70 + config.confidence_boost,
                                "detection_count": 1,
                                "is_active": True,
                                "last_seen": datetime.now(),
                                "detection_date": ioc_data.get("first_seen", "")[:10]
                                if ioc_data.get("first_seen")
                                else None,
                                "malware_family": ioc_data.get("malware", ""),
                                "threat_type": ioc_data.get("threat_type", ""),
                            }
                        )

            return {"success": True, "data": collected_ips}

        except Exception as e:
            return {"success": False, "error": str(e), "data": []}

    def _parse_text_feed(
        self, text_data: str, config: SourceConfig, max_ips: int
    ) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ í”¼ë“œ íŒŒì‹± (IP ëª©ë¡)"""
        collected_ips = []

        try:
            lines = text_data.strip().split("\n")
            ip_count = 0

            for line in lines:
                if ip_count >= max_ips:
                    break

                line = line.strip()

                # ì£¼ì„ì´ë‚˜ ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
                if not line or line.startswith("#") or line.startswith("//"):
                    continue

                # URLì—ì„œ í˜¸ìŠ¤íŠ¸ ì¶”ì¶œ (OpenPhishì˜ ê²½ìš°)
                if line.startswith("http"):
                    try:
                        from urllib.parse import urlparse

                        parsed = urlparse(line)
                        potential_ip = parsed.hostname
                    except:
                        potential_ip = line
                else:
                    potential_ip = line.split(":")[0]  # í¬íŠ¸ ì œê±°

                if self._is_valid_ip(potential_ip):
                    collected_ips.append(
                        {
                            "ip_address": potential_ip,
                            "source": config.name,
                            "reason": f"{config.name} ìœ„í˜‘ ëª©ë¡",
                            "category": config.category,
                            "confidence_level": 65 + config.confidence_boost,
                            "detection_count": 1,
                            "is_active": True,
                            "last_seen": datetime.now(),
                            "original_entry": line,
                        }
                    )
                    ip_count += 1

            return {"success": True, "data": collected_ips}

        except Exception as e:
            return {"success": False, "error": str(e), "data": []}

    def _parse_json_feed(
        self, json_data: Any, config: SourceConfig, max_ips: int
    ) -> Dict[str, Any]:
        """JSON í”¼ë“œ íŒŒì‹±"""
        collected_ips = []

        try:
            # ë°ì´í„° êµ¬ì¡° ë¶„ì„
            if isinstance(json_data, list):
                data_items = json_data
            elif isinstance(json_data, dict):
                # ì¼ë°˜ì ì¸ JSON êµ¬ì¡°ë“¤ ì‹œë„
                data_items = (
                    json_data.get("data")
                    or json_data.get("results")
                    or json_data.get("items")
                    or json_data.get("entries")
                    or [json_data]
                )
            else:
                data_items = []

            ip_count = 0
            for item in data_items:
                if ip_count >= max_ips:
                    break

                if not isinstance(item, dict):
                    continue

                # IP ì£¼ì†Œ ì¶”ì¶œ
                ip_address = None
                for field in [
                    config.ip_field,
                    "ip",
                    "ip_address",
                    "host",
                    "target",
                    "url",
                ]:
                    if field in item:
                        ip_candidate = str(item[field])

                        # URLì—ì„œ í˜¸ìŠ¤íŠ¸ ì¶”ì¶œ
                        if ip_candidate.startswith("http"):
                            try:
                                from urllib.parse import urlparse

                                parsed = urlparse(ip_candidate)
                                ip_candidate = parsed.hostname
                            except:
                                continue

                        if self._is_valid_ip(ip_candidate):
                            ip_address = ip_candidate
                            break

                if ip_address:
                    # ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
                    reason = item.get(
                        config.reason_field or "description", f"{config.name} ìœ„í˜‘"
                    )
                    detection_date = item.get(config.date_field or "date", "")

                    collected_ips.append(
                        {
                            "ip_address": ip_address,
                            "source": config.name,
                            "reason": reason,
                            "category": config.category,
                            "confidence_level": 60 + config.confidence_boost,
                            "detection_count": 1,
                            "is_active": True,
                            "last_seen": datetime.now(),
                            "detection_date": detection_date[:10]
                            if detection_date
                            else None,
                            "raw_data": json.dumps(item)[:500],  # ì›ë³¸ ë°ì´í„° ì¼ë¶€
                        }
                    )
                    ip_count += 1

            return {"success": True, "data": collected_ips}

        except Exception as e:
            return {"success": False, "error": str(e), "data": []}

    def _determine_category_from_threat_type(self, threat_type: str) -> str:
        """ìœ„í˜‘ íƒ€ì…ì—ì„œ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        threat_lower = threat_type.lower()

        if any(keyword in threat_lower for keyword in ["botnet", "c2", "command"]):
            return "botnet"
        elif any(keyword in threat_lower for keyword in ["phishing", "phish"]):
            return "phishing"
        elif any(keyword in threat_lower for keyword in ["malware", "trojan", "rat"]):
            return "malware"
        elif any(keyword in threat_lower for keyword in ["spam", "bulk"]):
            return "spam"
        else:
            return "malicious"

    def _is_valid_ip(self, ip_str: str) -> bool:
        """IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            import ipaddress

            if not ip_str:
                return False

            ip_obj = ipaddress.ip_address(ip_str.strip())

            # ì‚¬ì„¤ IP ë° íŠ¹ìˆ˜ IP í•„í„°ë§
            if ip_obj.is_private or ip_obj.is_loopback or ip_obj.is_multicast:
                return False

            return True

        except ValueError:
            return False

    def _deduplicate_and_enhance(
        self, all_data: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì œê±° ë° ë°ì´í„° í’ˆì§ˆ í–¥ìƒ"""

        # IP ì£¼ì†Œë³„ ê·¸ë£¹í™”
        ip_groups = {}
        for item in all_data:
            ip = item.get("ip_address")
            if ip:
                if ip not in ip_groups:
                    ip_groups[ip] = []
                ip_groups[ip].append(item)

        enhanced_data = []

        for ip, items in ip_groups.items():
            if len(items) == 1:
                # ë‹¨ì¼ ì†ŒìŠ¤
                enhanced_data.append(items[0])
            else:
                # ë‹¤ì¤‘ ì†ŒìŠ¤ - ì •ë³´ ë³‘í•©
                merged_item = self._merge_multiple_sources(items)
                enhanced_data.append(merged_item)

        return enhanced_data

    def _merge_multiple_sources(self, items: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ì†ŒìŠ¤ ì •ë³´ ë³‘í•©"""
        # ê¸°ì¤€ ì•„ì´í…œ (ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„)
        base_item = max(items, key=lambda x: x.get("confidence_level", 0))

        # ì†ŒìŠ¤ ëª©ë¡
        sources = [item.get("source", "Unknown") for item in items]

        # íƒì§€ íšŸìˆ˜ í•©ê³„
        total_detections = sum(item.get("detection_count", 1) for item in items)

        # í‰ê·  ì‹ ë¢°ë„ (ê°€ì¤‘í‰ê· )
        total_confidence = sum(item.get("confidence_level", 0) for item in items)
        avg_confidence = min(
            100, int(total_confidence / len(items)) + len(items) * 2
        )  # ë‹¤ì¤‘ ì†ŒìŠ¤ ë³´ë„ˆìŠ¤

        # ê°€ì¥ ìƒì„¸í•œ ì´ìœ 
        best_reason = max(items, key=lambda x: len(x.get("reason", "")))["reason"]

        # ê°€ì¥ ì´ë¥¸ íƒì§€ì¼
        detection_dates = [
            item.get("detection_date") for item in items if item.get("detection_date")
        ]
        earliest_date = min(detection_dates) if detection_dates else None

        # ë³‘í•©ëœ ì•„ì´í…œ
        merged = base_item.copy()
        merged.update(
            {
                "source": f"Multi-Source ({len(sources)}ê°œ)",
                "sources": sources,
                "reason": best_reason,
                "confidence_level": avg_confidence,
                "detection_count": total_detections,
                "detection_date": earliest_date,
                "multi_source": True,
                "source_count": len(sources),
            }
        )

        return merged

    def get_source_status(self) -> Dict[str, Any]:
        """ì†ŒìŠ¤ ìƒíƒœ ì •ë³´"""
        active_sources = []
        inactive_sources = []

        for source_id, config in self.sources.items():
            source_info = {
                "id": source_id,
                "name": config.name,
                "type": config.source_type.value,
                "priority": config.priority,
                "rate_limit": config.rate_limit,
                "confidence_boost": config.confidence_boost,
            }

            if config.enabled:
                active_sources.append(source_info)
            else:
                inactive_sources.append(source_info)

        return {
            "total_sources": len(self.sources),
            "active_sources": len(active_sources),
            "inactive_sources": len(inactive_sources),
            "active_source_list": active_sources,
            "inactive_source_list": inactive_sources,
            "collection_stats": self.collection_stats,
        }

    def enable_source(self, source_type: str, enabled: bool = True):
        """ì†ŒìŠ¤ í™œì„±í™”/ë¹„í™œì„±í™”"""
        for source_id, config in self.sources.items():
            if source_type.lower() in source_id.lower():
                config.enabled = enabled
                logger.info(
                    f"{'âœ…' if enabled else 'âŒ'} ì†ŒìŠ¤ {config.name} {'í™œì„±í™”' if enabled else 'ë¹„í™œì„±í™”'}"
                )
                return True
        return False

    def add_custom_source(
        self,
        name: str,
        url: str,
        source_type: SourceType = SourceType.CUSTOM_API,
        **kwargs,
    ) -> bool:
        """ì‚¬ìš©ì ì •ì˜ ì†ŒìŠ¤ ì¶”ê°€"""
        try:
            config = SourceConfig(source_type=source_type, name=name, url=url, **kwargs)
            self.add_source(config)
            return True
        except Exception as e:
            logger.error(f"âŒ ì‚¬ìš©ì ì •ì˜ ì†ŒìŠ¤ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
multi_source_collector = MultiSourceCollector()
