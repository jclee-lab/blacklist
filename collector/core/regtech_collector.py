"""
REGTECH Collector Service
REGTECH í¬í„¸ì—ì„œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ IP ìˆ˜ì§‘
"""

import logging
import requests
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from collector.config import CollectorConfig
from collector.core.rate_limiter import regtech_rate_limiter

logger = logging.getLogger(__name__)


class RegtechCollector:
    """ê³ ì„±ëŠ¥ REGTECH ìˆ˜ì§‘ê¸° í´ë˜ìŠ¤ - ìµœì í™”ëœ ìˆ˜ì§‘ ë° ì²˜ë¦¬"""

    def __init__(self):
        self.base_url = CollectorConfig.REGTECH_BASE_URL
        self.session = requests.Session()

        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        self.session.headers.update(
            {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept-Encoding": "gzip, deflate",
                "Connection": "keep-alive",
            }
        )

        # ì„¸ì…˜ ìµœì í™”
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10, pool_maxsize=20, max_retries=3, pool_block=False
        )
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)

        self.authenticated = False
        self._auth_cache = {}  # ì¸ì¦ ìƒíƒœ ìºì‹œ
        self._data_cache = {}  # ë°ì´í„° ìºì‹œ
        self._cache_ttl = 300  # 5ë¶„ ìºì‹œ TTL

        # Rate Limiter í†µí•© (ì™¸ë¶€ API ì°¨ë‹¨ ë°©ì§€)
        self.rate_limiter = regtech_rate_limiter
        logger.info("ğŸš¦ Rate Limiter í†µí•©: API ì°¨ë‹¨ ë°©ì§€ í™œì„±í™”")

    def authenticate(self, username: str, password: str) -> bool:
        """REGTECH í¬í„¸ 2ë‹¨ê³„ ì¸ì¦ - findOneMember + addLogin"""
        auth_key = f"{username}:{hash(password)}"

        # ìºì‹œëœ ì¸ì¦ í™•ì¸
        if auth_key in self._auth_cache:
            cache_time, is_valid = self._auth_cache[auth_key]
            if time.time() - cache_time < self._cache_ttl and is_valid:
                self.authenticated = True
                logger.info("âœ… ìºì‹œëœ REGTECH ì¸ì¦ ì‚¬ìš©")
                return True

        max_retries = 3
        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ” REGTECH ì§ì ‘ ì¸ì¦ ì‹œë„ {attempt + 1}/{max_retries}")

                # Rate Limiting ì ìš© (API ì°¨ë‹¨ ë°©ì§€)
                logger.info("ğŸš¦ Rate Limiter ëŒ€ê¸° ì¤‘...")
                self.rate_limiter.wait_if_needed()

                # ë§¤ ì‹œë„ë§ˆë‹¤ ìƒˆ ì„¸ì…˜ ìƒì„± (ì‹¤íŒ¨í•œ ì¿ í‚¤ ë°©ì§€)
                self.session = requests.Session()

                # Python requestsê°€ ì‹¤íŒ¨í•˜ë¯€ë¡œ ì§ì ‘ curl ì‚¬ìš© (curl í…ŒìŠ¤íŠ¸ì—ì„œ 100% ì„±ê³µ í™•ì¸)
                logger.info("ğŸ“¡ ë¡œê·¸ì¸: curl ì§ì ‘ í˜¸ì¶œ ë°©ì‹")

                import subprocess
                import json

                # í™˜ê²½ë³€ìˆ˜ ê°’ ë””ë²„ê¹…
                logger.info(f"ğŸ” username: '{username}' (length: {len(username)})")
                logger.info(f"ğŸ” password: '{password}' (length: {len(password)})")

                curl_cmd = [
                    'curl', '-s', '-i', '-X', 'POST',
                    f'{self.base_url}/login/addLogin',
                    '-H', 'Content-Type: application/x-www-form-urlencoded',
                    '-d', f'username={username}&password={password}'
                ]

                logger.info(f"ğŸ” curl command: {' '.join(curl_cmd)}")

                result = subprocess.run(curl_cmd, capture_output=True, text=True, timeout=20)

                # ì‘ë‹µ íŒŒì‹±
                response_text = result.stdout
                headers_section, _, body_section = response_text.partition('\r\n\r\n')

                # ìƒíƒœ ì½”ë“œ ì¶”ì¶œ
                status_line = headers_section.split('\n')[0]
                status_code = int(status_line.split()[1])

                # ì¿ í‚¤ ì¶”ì¶œ
                jwt_cookie = None
                session_cookie = None
                for line in headers_section.split('\n'):
                    if line.startswith('Set-Cookie: regtech-va='):
                        jwt_cookie = line.split('=', 1)[1].split(';')[0]
                    elif line.startswith('Set-Cookie: regtech-front='):
                        session_cookie = line.split('=', 1)[1].split(';')[0]

                # Location í—¤ë” ì¶”ì¶œ
                location = None
                for line in headers_section.split('\n'):
                    if line.startswith('Location: '):
                        location = line.split(':', 1)[1].strip()

                logger.info(f"ğŸ“Š ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {status_code}")
                logger.info(f"ğŸ“Š Location: {location}")
                logger.info(f"ğŸ“Š JWT í† í° ì¡´ì¬: {jwt_cookie is not None}")

                # ì„±ê³µ ì¡°ê±´: 302 + JWT í† í° + /main/main ë¦¬ë‹¤ì´ë ‰íŠ¸
                if status_code == 302 and jwt_cookie and location == '/main/main':
                    self.authenticated = True
                    # ì„¸ì…˜ì— ì¿ í‚¤ ì €ì¥ - domainê³¼ path ëª…ì‹œ
                    if jwt_cookie:
                        self.session.cookies.set('regtech-va', jwt_cookie, domain='regtech.fsec.or.kr', path='/')
                        logger.info(f"ğŸª JWT ì¿ í‚¤ ì„¤ì •: regtech-va")
                    if session_cookie:
                        self.session.cookies.set('regtech-front', session_cookie, domain='regtech.fsec.or.kr', path='/')
                        logger.info(f"ğŸª ì„¸ì…˜ ì¿ í‚¤ ì„¤ì •: regtech-front")

                    logger.info(f"âœ… REGTECH ì¸ì¦ ì„±ê³µ (curl ì§ì ‘ í˜¸ì¶œ)")
                    logger.info(f"ğŸ”‘ JWT í† í°: {jwt_cookie[:50]}...")
                    logger.info(f"ğŸª ì´ ì„¸ì…˜ ì¿ í‚¤: {len(self.session.cookies)}ê°œ")

                    # ì¿ í‚¤ í™•ì¸
                    for cookie in self.session.cookies:
                        logger.info(f"  - {cookie.name}: {cookie.value[:30]}... (domain={cookie.domain}, path={cookie.path})")

                    self._auth_cache[auth_key] = (time.time(), True)

                    # Rate Limiter ì„±ê³µ í”¼ë“œë°±
                    self.rate_limiter.on_success()
                    return True
                else:
                    logger.warning(f"âš ï¸ ì¸ì¦ ì‹¤íŒ¨:")
                    logger.warning(f"  - ìƒíƒœ ì½”ë“œ: {status_code}")
                    logger.warning(f"  - Location: {location}")
                    logger.warning(f"  - JWT í† í°: {jwt_cookie is not None}")

                    # Rate Limiter ì‹¤íŒ¨ í”¼ë“œë°±
                    self.rate_limiter.on_failure(error_code=status_code if status_code >= 400 else None)

                    if attempt < max_retries - 1:
                        continue  # ë°±ì˜¤í”„ëŠ” rate_limiter.on_failure()ì—ì„œ ì²˜ë¦¬ë¨
                    else:
                        return False

            except Exception as e:
                logger.warning(f"âš ï¸ ì¸ì¦ ì‹œë„ {attempt + 1} ì˜¤ë¥˜: {e}")

                # Rate Limiter ì‹¤íŒ¨ í”¼ë“œë°±
                self.rate_limiter.on_failure()

                if attempt < max_retries - 1:
                    continue  # ë°±ì˜¤í”„ëŠ” rate_limiter.on_failure()ì—ì„œ ì²˜ë¦¬ë¨

        # ì¸ì¦ ì‹¤íŒ¨ ìºì‹œ
        self._auth_cache[auth_key] = (time.time(), False)
        logger.error("âŒ REGTECH 2ë‹¨ê³„ ì¸ì¦ ì™„ì „ ì‹¤íŒ¨")
        return False

    def collect_blacklist_data(
        self,
        page_size: int = 2000,
        start_date: str = None,
        end_date: str = None,
        max_pages: int = 100,
    ) -> List[Dict[str, Any]]:
        """ìŠ¤ë§ˆíŠ¸ ë‹¤ë‹¨ê³„ ë‚ ì§œ ë²”ìœ„ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘"""
        if not self.authenticated:
            logger.error("âŒ ì¸ì¦ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ ìˆ˜ì§‘ ì‹œë„")
            return []

        collection_start = time.time()
        collected_data = []

        # ìŠ¤ë§ˆíŠ¸ ë‚ ì§œ ë²”ìœ„ ì „ëµ êµ¬í˜„
        date_strategies = self._generate_date_strategies(start_date, end_date)

        try:
            logger.info(
                f"ğŸš€ ìŠ¤ë§ˆíŠ¸ REGTECH ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (í˜ì´ì§€ í¬ê¸°: {page_size}, ìµœëŒ€ í˜ì´ì§€: {max_pages} - ì œí•œ í•´ì œ)"
            )
            logger.info(f"ğŸ“… ë‚ ì§œ ì „ëµ ìˆ˜: {len(date_strategies)}ê°œ")

            # ë‹¤ë‹¨ê³„ ë‚ ì§œ ë²”ìœ„ ì‹œë„
            for strategy_idx, (strategy_name, start_dt, end_dt) in enumerate(
                date_strategies, 1
            ):
                logger.info(
                    f"ğŸ”„ ì „ëµ {strategy_idx}/{len(date_strategies)}: {strategy_name} ({start_dt} ~ {end_dt})"
                )

                strategy_data = []
                for page_num in range(1, max_pages + 1):
                    page_data = self._collect_single_page(
                        page_num, page_size, start_dt, end_dt
                    )

                    if not page_data:
                        logger.info(f"ğŸ“„ ì „ëµ {strategy_name} í˜ì´ì§€ {page_num}: ë°ì´í„° ì—†ìŒ")
                        break

                    strategy_data.extend(page_data)
                    logger.info(
                        f"ğŸ“„ ì „ëµ {strategy_name} í˜ì´ì§€ {page_num}: {len(page_data)}ê°œ IP ìˆ˜ì§‘"
                    )

                    # í˜ì´ì§€ ê°„ ê°„ê²©ì€ Rate Limiterê°€ ìë™ ì²˜ë¦¬

                    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ í•´ì œ (ë¬´ì œí•œ ìˆ˜ì§‘)
                    if len(strategy_data) >= 10000000:  # 1000ë§Œê°œë¡œ ëŒ€í­ ì¦ê°€
                        logger.warning("âš ï¸ ë©”ëª¨ë¦¬ í•œê³„ ë„ë‹¬ (1000ë§Œê°œ), í˜„ì¬ ì „ëµ ì¤‘ë‹¨")
                        break

                if strategy_data:
                    logger.info(f"âœ… ì „ëµ {strategy_name} ì„±ê³µ: {len(strategy_data)}ê°œ IP ìˆ˜ì§‘")
                    collected_data.extend(strategy_data)
                    break  # ì²« ë²ˆì§¸ ì„±ê³µí•œ ì „ëµìœ¼ë¡œ ì¶©ë¶„
                else:
                    logger.warning(f"âš ï¸ ì „ëµ {strategy_name} ì‹¤íŒ¨: ë°ì´í„° ì—†ìŒ")

                # ì „ëµ ê°„ ê°„ê²©ì€ Rate Limiterê°€ ìë™ ì²˜ë¦¬

            collection_time = time.time() - collection_start
            logger.info(
                f"âœ… ìŠ¤ë§ˆíŠ¸ REGTECH ìˆ˜ì§‘ ì™„ë£Œ: {len(collected_data)}ê°œ IP ({collection_time:.2f}ì´ˆ)"
            )

            # ìˆ˜ì§‘ ì„±ê³¼ ê¸°ë¡
            self._record_collection_performance(
                collected_data, date_strategies, collection_time
            )

            # ìˆ˜ì§‘ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ í›„ì²˜ë¦¬
            return self._post_process_collected_data(collected_data)

        except Exception as e:
            logger.error(f"âŒ REGTECH ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            return collected_data  # ë¶€ë¶„ ìˆ˜ì§‘ëœ ë°ì´í„°ë¼ë„ ë°˜í™˜  # ë¶€ë¶„ ìˆ˜ì§‘ëœ ë°ì´í„°ë¼ë„ ë°˜í™˜

    def _generate_date_strategies(
        self, start_date: str = None, end_date: str = None
    ) -> List[tuple]:
        """ìŠ¤ë§ˆíŠ¸ ë‚ ì§œ ë²”ìœ„ ì „ëµ ìƒì„± - ë°ì´í„° ê°€ìš©ì„± ìµœì í™”"""
        strategies = []

        # ë‚ ì§œ í•„í„° ì—†ì´ ì „ì²´ ìˆ˜ì§‘ ëª¨ë“œ (REGTECH ì›¹ì‚¬ì´íŠ¸ëŠ” ë‚ ì§œ ì—†ì„ ë•Œ ì „ì²´ ë°ì´í„° ë°˜í™˜)
        if start_date is None and end_date is None:
            strategies.append(("ì „ì²´ ë°ì´í„°", None, None))
            logger.info(f"ğŸ“‹ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“œ í™œì„±í™” (ë‚ ì§œ í•„í„° ì—†ìŒ)")
            return strategies

        today = datetime.now()

        # ê¸°ë³¸ ë‚ ì§œ ì„¤ì •
        if not end_date:
            end_date = today.strftime("%Y-%m-%d")

        # ì „ëµ 1: ìµœê·¼ 1ì¼ (ì¼ì¼ ë°ì´í„° - ì •ê¸° ìˆ˜ì§‘ìš©)
        recent_start = (today - timedelta(days=1)).strftime("%Y-%m-%d")
        strategies.append(("ìµœê·¼ 1ì¼ ì¼ì¼", recent_start, end_date))

        # ì „ëµ 2: ìµœê·¼ 90ì¼ (ë¶„ê¸° ë°ì´í„° - ì´ˆê¸° ìˆ˜ì§‘ìš©)
        quarter_start = (today - timedelta(days=90)).strftime("%Y-%m-%d")
        strategies.append(("ìµœê·¼ 90ì¼ ë¶„ê¸°", quarter_start, end_date))

        # ì „ëµ 3: ì‚¬ìš©ì ì§€ì • ë²”ìœ„ (ìˆëŠ” ê²½ìš°)
        if start_date:
            strategies.insert(0, ("ì‚¬ìš©ì ì§€ì •", start_date, end_date))

        logger.info(f"ğŸ“‹ ìƒì„±ëœ ë‚ ì§œ ì „ëµ: {[s[0] for s in strategies]}")
        return strategies

    def _record_collection_performance(
        self, collected_data: List[Dict], strategies: List[tuple], duration: float
    ):
        """ìˆ˜ì§‘ ì„±ê³¼ ê¸°ë¡ ë° ë¶„ì„"""
        performance_log = {
            "timestamp": datetime.now().isoformat(),
            "total_strategies": len(strategies),
            "successful_collection": len(collected_data) > 0,
            "data_count": len(collected_data),
            "duration_seconds": round(duration, 2),
            "strategies_tried": [s[0] for s in strategies],
            "success_rate": (1 if len(collected_data) > 0 else 0) / len(strategies),
        }

        logger.info(f"ğŸ“Š ìˆ˜ì§‘ ì„±ê³¼: {performance_log}")

        # ì„±ê³¼ ë°ì´í„°ë¥¼ ìºì‹œì— ì €ì¥ (í–¥í›„ ìµœì í™”ìš©)
        self._performance_cache = getattr(self, "_performance_cache", [])
        self._performance_cache.append(performance_log)

        # ìµœê·¼ 10ê°œ ì„±ê³¼ë§Œ ìœ ì§€
        if len(self._performance_cache) > 10:
            self._performance_cache = self._performance_cache[-10:]

    def _collect_single_page(
        self,
        page_num: int,
        page_size: int,
        start_date: str = None,
        end_date: str = None,
    ) -> List[Dict[str, Any]]:
        """HAR ë¶„ì„ ê¸°ë°˜ ë‹¨ì¼ í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘ - ì‹¤ì œ í”„ë¡œí† ì½œ êµ¬í˜„"""
        try:
            # HAR ë¶„ì„ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ì—”ë“œí¬ì¸íŠ¸
            data_url = f"{self.base_url}/fcti/securityAdvisory/advisoryList"

            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"page_{page_num}_{page_size}_{start_date}_{end_date}"
            if cache_key in self._data_cache:
                cache_time, cached_data = self._data_cache[cache_key]
                if time.time() - cache_time < 60:  # 1ë¶„ ìºì‹œ
                    logger.info(f"ğŸ“¦ í˜ì´ì§€ {page_num} ìºì‹œ ì‚¬ìš©")
                    return cached_data

            # HAR ë¶„ì„ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ìš”ì²­ ë°ì´í„° êµ¬ì¡°
            request_data = {
                "page": str(page_num - 1),  # 0-based ì¸ë±ì‹±
                "tabSort": "blacklist",
                "excelDownload": "",
                "cveId": "",
                "ipId": "",
                "estId": "",
                "startDate": start_date or "",
                "endDate": end_date or "",
                "findCondition": "all",
                "findKeyword": "",
                "excelDown": "blacklist",
                "size": str(page_size),
            }

            # HAR ë¶„ì„ì—ì„œ í™•ì¸ëœ ì •í™•í•œ í—¤ë”
            headers = {
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                "Accept-Encoding": "gzip, deflate, br, zstd",
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Content-Type": "application/x-www-form-urlencoded",
                "Origin": "https://regtech.fsec.or.kr",
                "Pragma": "no-cache",
                "Referer": "https://regtech.fsec.or.kr/fcti/securityAdvisory/advisoryList",
                "Sec-Fetch-Dest": "document",
                "Sec-Fetch-Mode": "navigate",
                "Sec-Fetch-Site": "same-origin",
                "Sec-Fetch-User": "?1",
                "Upgrade-Insecure-Requests": "1",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
            }

            logger.info(f"ğŸ”„ HAR ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘: í˜ì´ì§€ {page_num}, í¬ê¸° {page_size}")

            # Rate Limiting ì ìš© (API ì°¨ë‹¨ ë°©ì§€)
            self.rate_limiter.wait_if_needed()

            # ì¿ í‚¤ í™•ì¸ ë¡œê·¸
            cookie_count = len(self.session.cookies)
            has_jwt = any(c.name == 'regtech-va' for c in self.session.cookies)
            logger.info(f"ğŸª ìš”ì²­ ì¿ í‚¤ ìƒíƒœ: {cookie_count}ê°œ, JWT ì¡´ì¬: {has_jwt}")

            # ë°ì´í„° ìš”ì²­ - HAR ë¶„ì„ ê¸°ë°˜
            response = self.session.post(
                data_url,
                data=request_data,
                headers=headers,
                timeout=45,
                allow_redirects=True,
            )

            logger.info(f"ğŸ“Š ì‘ë‹µ ìƒíƒœ: {response.status_code}, URL: {response.url}")

            if response.status_code == 200:
                page_data = self._parse_response_data(response)

                # ê²°ê³¼ ìºì‹œ
                self._data_cache[cache_key] = (time.time(), page_data)

                # Rate Limiter ì„±ê³µ í”¼ë“œë°±
                self.rate_limiter.on_success()

                logger.info(f"âœ… í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì™„ë£Œ: {len(page_data)}ê°œ í•­ëª©")
                return page_data
            else:
                logger.warning(f"âš ï¸ í˜ì´ì§€ {page_num} ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")

                # Rate Limiter ì‹¤íŒ¨ í”¼ë“œë°±
                self.rate_limiter.on_failure(error_code=response.status_code)

                return []

        except Exception as e:
            logger.error(f"âŒ í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

            # Rate Limiter ì‹¤íŒ¨ í”¼ë“œë°±
            self.rate_limiter.on_failure()

            return []

    def _parse_response_data(self, response) -> List[Dict[str, Any]]:
        """ì‘ë‹µ ë°ì´í„° íŒŒì‹± - ìµœì í™”ëœ ì²˜ë¦¬"""
        try:
            # JSON íŒŒì‹± ì‹œë„
            json_data = response.json()

            if isinstance(json_data, dict) and "data" in json_data:
                raw_data = json_data["data"]
            elif isinstance(json_data, list):
                raw_data = json_data
            else:
                logger.warning("âš ï¸ ì˜ˆìƒí•˜ì§€ ëª»í•œ JSON ì‘ë‹µ í˜•ì‹")
                return self._parse_html_response(response.text)

            # ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
            processed_data = []
            for item in raw_data:
                processed_item = self._process_regtech_item(item)
                if processed_item:
                    processed_data.append(processed_item)

            return processed_data

        except json.JSONDecodeError:
            logger.info("ğŸ“„ JSON íŒŒì‹± ì‹¤íŒ¨, HTML íŒŒì‹±ìœ¼ë¡œ ì „í™˜")
            return self._parse_html_response(response.text)
        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []

    def _post_process_collected_data(
        self, collected_data: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ìˆ˜ì§‘ëœ ë°ì´í„° í›„ì²˜ë¦¬ - ìµœì í™” ë° ì •ì œ"""
        if not collected_data:
            return []

        logger.info(f"ğŸ”§ ìˆ˜ì§‘ ë°ì´í„° í›„ì²˜ë¦¬ ì‹œì‘: {len(collected_data)}ê°œ í•­ëª©")

        # 1. IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì‚¬ ë° ì •ì œ
        valid_data = []
        for item in collected_data:
            ip_addr = item.get("ip_address", "").strip()
            if self._is_valid_ip(ip_addr):
                # IP ì •ê·œí™”
                item["ip_address"] = ip_addr
                valid_data.append(item)

        # 2. ì¤‘ë³µ ì œê±° (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        unique_data = self._fast_deduplication(valid_data)

        # 3. ë°ì´í„° í’ˆì§ˆ í–¥ìƒ
        enhanced_data = []
        for item in unique_data:
            enhanced_item = self._enhance_data_quality(item)
            enhanced_data.append(enhanced_item)

        logger.info(f"âœ… í›„ì²˜ë¦¬ ì™„ë£Œ: {len(enhanced_data)}ê°œ ê³ í’ˆì§ˆ IP")
        return enhanced_data

    def _fast_deduplication(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ê³ ì† ì¤‘ë³µ ì œê±°"""
        seen_ips = set()
        unique_data = []

        for item in data:
            ip_key = f"{item.get('ip_address')}:{item.get('source', 'REGTECH')}"
            if ip_key not in seen_ips:
                seen_ips.add(ip_key)
                unique_data.append(item)

        return unique_data

    def _enhance_data_quality(self, item: Dict[str, Any]) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ í–¥ìƒ - í•´ì œì¼ ê¸°ì¤€ í™œì„± ìƒíƒœ ë¡œì§ ì ìš©"""

        # í•´ì œì¼ ì¶”ì¶œ
        removal_date = self._parse_date(item.get("removal_date"))

        # í™œì„± ìƒíƒœ ê²°ì • (removal_date ê¸°ë°˜)
        is_active = True
        if removal_date:
            # í•´ì œì¼ì´ ì˜¤ëŠ˜ë³´ë‹¤ ì´ì „ì´ë©´ ë¹„í™œì„±í™”
            today = datetime.now().date()
            if isinstance(removal_date, str):
                removal_date_obj = datetime.strptime(removal_date, "%Y-%m-%d").date()
            else:
                removal_date_obj = (
                    removal_date.date()
                    if hasattr(removal_date, "date")
                    else removal_date
                )

            if removal_date_obj <= today:
                is_active = False
                logger.info(
                    f"ğŸ”´ [í’ˆì§ˆí–¥ìƒ] IP {item.get('ip_address')} ë¹„í™œì„±í™”: í•´ì œì¼ {removal_date_obj} <= ì˜¤ëŠ˜ {today}"
                )

        # ê¸°ë³¸ê°’ ì„¤ì • ë° ë°ì´í„° ì •ì œ - ì›ë³¸ reason ìš°ì„  ë³´ì¡´
        original_reason = item.get("reason", "")
        if not original_reason or original_reason in [
            "REGTECH HTML Parse",
            "REGTECH Blacklist",
        ]:
            # ì¶”ê°€ í•„ë“œì—ì„œ ì˜ë¯¸ ìˆëŠ” ë‚´ìš© ì°¾ê¸°
            for alt_field in [
                "contents",
                "detail",
                "description",
                "threat_desc",
                "block_reason",
            ]:
                alt_content = item.get(alt_field, "").strip()
                if alt_content and len(alt_content) > 5:  # ì˜ë¯¸ ìˆëŠ” ê¸¸ì´
                    original_reason = alt_content
                    break
            if not original_reason:
                original_reason = "REGTECH ìœ„í˜‘ IP"

        enhanced_item = {
            "ip_address": item.get("ip_address", "").strip(),
            "source": "REGTECH",
            "reason": original_reason,
            "confidence_level": self._determine_confidence(item),
            "detection_count": 1,
            "is_active": is_active,  # í•´ì œì¼ ê¸°ì¤€ ë¡œì§ ì ìš©
            "last_seen": datetime.now(),
            "country": self._normalize_country_code(item.get("country")),
            "detection_date": self._parse_date(item.get("detection_date")),
            "removal_date": removal_date,
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            "collection_timestamp": datetime.now().isoformat(),
            "data_source_version": "optimized_v2.0",
        }

        return enhanced_item

    def _normalize_country_code(self, country_value) -> Optional[str]:
        """êµ­ê°€ ì½”ë“œ ì •ê·œí™”"""
        if not country_value:
            return None

        country_str = str(country_value).upper().strip()

        # ì¼ë°˜ì ì¸ êµ­ê°€ ì½”ë“œ ë§¤í•‘
        country_mapping = {
            "KR": "KR",
            "KOREA": "KR",
            "í•œêµ­": "KR",
            "US": "US",
            "USA": "US",
            "UNITED STATES": "US",
            "CN": "CN",
            "CHINA": "CN",
            "ì¤‘êµ­": "CN",
            "JP": "JP",
            "JAPAN": "JP",
            "ì¼ë³¸": "JP",
        }

        return country_mapping.get(
            country_str, country_str[:2] if len(country_str) >= 2 else None
        )

    def _process_regtech_item(self, item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """REGTECH ë°ì´í„° í•­ëª© ì²˜ë¦¬ - ìµœì í™”"""
        try:
            # IP ì£¼ì†Œ ì¶”ì¶œ - ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›
            ip_fields = ["ipAddr", "ip_address", "ip", "IP", "target_ip"]
            ip_address = None

            for field in ip_fields:
                if field in item and item[field]:
                    ip_address = str(item[field]).strip()
                    break

            if not ip_address or not self._is_valid_ip(ip_address):
                return None

            # ì›ë³¸ ë°ì´í„° ë¡œê¹… ë° ê²€ì¦
            logger.info(f"ğŸ” ì›ë³¸ REGTECH ë°ì´í„°: {item}")

            # íƒì§€ì¼/í•´ì œì¼ í•„ë“œ í™•ì¸
            detection_fields = [
                "regDt",
                "detectionDate",
                "reg_dt",
                "detect_dt",
                "created_dt",
            ]
            removal_fields = ["delDt", "removalDate", "del_dt", "remove_dt", "end_dt"]
            reason_fields = [
                "blockReason",
                "reason",
                "block_reason",
                "description",
                "content",
            ]

            detection_date = None
            removal_date = None
            detection_reason = "REGTECH Blacklist"

            # íƒì§€ì¼ ì¶”ì¶œ
            for field in detection_fields:
                if field in item and item[field]:
                    detection_date = self._parse_date(item[field])
                    logger.info(
                        f"âœ… íƒì§€ì¼ ë°œê²¬: {field} = {item[field]} -> {detection_date}"
                    )
                    break

            # í•´ì œì¼ ì¶”ì¶œ
            for field in removal_fields:
                if field in item and item[field]:
                    removal_date = self._parse_date(item[field])
                    logger.info(f"âœ… í•´ì œì¼ ë°œê²¬: {field} = {item[field]} -> {removal_date}")
                    break

            # íƒì§€ë‚´ìš© ì¶”ì¶œ - ì›ë³¸ raw data ìš°ì„ 
            for field in reason_fields:
                if field in item and item[field]:
                    raw_reason = str(item[field]).strip()
                    if raw_reason and raw_reason not in [
                        "REGTECH HTML Parse",
                        "REGTECH Blacklist",
                        "",
                    ]:
                        detection_reason = raw_reason
                        logger.info(f"âœ… ì›ë³¸ íƒì§€ë‚´ìš© ë°œê²¬: {field} = {detection_reason}")
                        break
                    elif raw_reason:
                        # ê¸°ë³¸ê°’ë³´ë‹¤ëŠ” ì˜ë¯¸ ìˆëŠ” ë‚´ìš©ì´ë©´ ì‚¬ìš©
                        detection_reason = raw_reason
                        logger.info(f"ğŸ“ ê¸°ë³¸ íƒì§€ë‚´ìš© ì‚¬ìš©: {field} = {detection_reason}")

            # ì¶”ê°€ í•„ë“œì—ì„œ ë” ìì„¸í•œ ë‚´ìš© ì°¾ê¸°
            additional_content_fields = [
                "contents",
                "detail",
                "description",
                "threat_desc",
                "attack_info",
                "malware_name",
            ]
            for field in additional_content_fields:
                if field in item and item[field]:
                    additional_content = str(item[field]).strip()
                    if additional_content and len(additional_content) > len(
                        detection_reason
                    ):
                        detection_reason = additional_content
                        logger.info(f"âœ… ìƒì„¸ íƒì§€ë‚´ìš© ë°œê²¬: {field} = {detection_reason}")
                        break

            # í™œì„± ìƒíƒœ ê²°ì • (removal_date ê¸°ë°˜)
            is_active = True
            if removal_date:
                # í•´ì œì¼ì´ ì˜¤ëŠ˜ë³´ë‹¤ ì´ì „ì´ë©´ ë¹„í™œì„±í™”
                today = datetime.now().date()
                if isinstance(removal_date, str):
                    removal_date_obj = datetime.strptime(
                        removal_date, "%Y-%m-%d"
                    ).date()
                else:
                    removal_date_obj = (
                        removal_date.date()
                        if hasattr(removal_date, "date")
                        else removal_date
                    )

                if removal_date_obj <= today:
                    is_active = False
                    logger.info(
                        f"ğŸ”´ IP {ip_address} ë¹„í™œì„±í™”: í•´ì œì¼ {removal_date_obj} <= ì˜¤ëŠ˜ {today}"
                    )

            # íš¨ìœ¨ì ì¸ ë°ì´í„° êµ¬ì¡°í™”
            processed_item = {
                "ip_address": ip_address,
                "source": "REGTECH",
                "reason": detection_reason,
                "confidence_level": self._determine_confidence(item),
                "detection_count": 1,
                "is_active": is_active,
                "last_seen": datetime.now(),
                "country": item.get("country") or item.get("countryCode"),
                "detection_date": detection_date,
                "removal_date": removal_date,
                "original_data": str(item)[:500],  # ì›ë³¸ ë°ì´í„° ì¼ë¶€ ì €ì¥
            }

            return processed_item

        except Exception as e:
            logger.debug(f"í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
            return None

    def _determine_confidence(self, item: Dict[str, Any]) -> int:
        """ì‹ ë¢°ë„ ê²°ì • - í–¥ìƒëœ í‰ê°€"""
        base_confidence = 80  # REGTECH ê¸°ë³¸ ì‹ ë¢°ë„

        # ìœ„í˜‘ ë ˆë²¨ ê¸°ë°˜ ì¡°ì •
        threat_level = str(item.get("threatLevel", "medium")).lower()
        threat_adjustments = {"critical": 15, "high": 10, "medium": 0, "low": -10}

        confidence = base_confidence + threat_adjustments.get(threat_level, 0)

        # ì¶”ê°€ ì‹ ë¢°ë„ ìš”ì†Œ
        if item.get("verified"):
            confidence += 5
        if item.get("reportCount", 0) > 10:
            confidence += 5

        return max(10, min(100, confidence))

    def _parse_date(self, date_str: str) -> Optional[str]:
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± - í–¥ìƒëœ ì²˜ë¦¬ ë° ë¡œê¹…"""
        if not date_str:
            return None

        # ì›ë³¸ ë°ì´í„° ë¡œê¹…
        logger.info(f"ğŸ“… ë‚ ì§œ íŒŒì‹± ì‹œë„: '{date_str}' (íƒ€ì…: {type(date_str)})")

        # ë¬¸ìì—´ë¡œ ë³€í™˜
        date_str = str(date_str).strip()

        date_formats = [
            "%Y-%m-%d",
            "%Y-%m-%d %H:%M:%S",
            "%Y/%m/%d",
            "%Y.%m.%d",
            "%d-%m-%Y",
            "%d/%m/%Y",
            "%d.%m.%Y",
            "%Y%m%d",  # 8ìë¦¬ ìˆ«ì
            "%m/%d/%Y",
            "%m-%d-%Y",
        ]

        for fmt in date_formats:
            try:
                parsed_date = datetime.strptime(date_str, fmt)
                result = parsed_date.strftime("%Y-%m-%d")
                logger.info(f"âœ… ë‚ ì§œ íŒŒì‹± ì„±ê³µ: '{date_str}' -> '{result}' (í˜•ì‹: {fmt})")
                return result
            except ValueError:
                continue

        logger.warning(f"âŒ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: '{date_str}' - ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹")
        return None

    def _parse_html_response(self, html_content: str) -> List[Dict[str, Any]]:
        """HTML ì‘ë‹µ íŒŒì‹± - ë‚ ì§œ ì •ë³´ í¬í•¨ í–¥ìƒëœ ì¶”ì¶œ"""
        try:
            soup = BeautifulSoup(html_content, "html.parser")
            collected_data = []

            # í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ (ê°œì„ ëœ ë‹¤ì¤‘ ì—´ íŒŒì‹±)
            tables = soup.find_all("table")
            for table in tables:
                # í—¤ë” ë¶„ì„
                header_row = table.find("tr")
                headers = []
                if header_row:
                    headers = [
                        th.get_text(strip=True).lower()
                        for th in header_row.find_all(["th", "td"])
                    ]
                    logger.info(f"ğŸ” í…Œì´ë¸” í—¤ë” ë°œê²¬: {headers}")

                rows = table.find_all("tr")[1:]  # í—¤ë” ì œì™¸

                for row_idx, row in enumerate(rows):
                    cells = row.find_all(["td", "th"])
                    if len(cells) >= 1:
                        # ëª¨ë“  ì…€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        cell_texts = [cell.get_text(strip=True) for cell in cells]

                        # IP ì£¼ì†Œ ì°¾ê¸° (ì²« ë²ˆì§¸ ë˜ëŠ” ë‹¤ë¥¸ ì—´ì—ì„œ)
                        ip_address = None
                        detection_date = None
                        removal_date = None
                        reason = "REGTECH HTML Parse"

                        for i, cell_text in enumerate(cell_texts):
                            if self._is_valid_ip(cell_text):
                                ip_address = cell_text
                                break

                        if ip_address:
                            # RAW ë°ì´í„° êµ¬ì¡° ê¸°ë°˜ ì§ì ‘ íŒŒì‹± (ìš°ì„ )
                            # ì˜ˆìƒ êµ¬ì¡°: [IP, êµ­ê°€, íƒì§€ë‚´ìš©, íƒì§€ì¼, í•´ì œì¼, ê¸°íƒ€...]
                            if len(cell_texts) >= 5:
                                # ìœ„ì¹˜ ê¸°ë°˜ ì •ë³´ ì¶”ì¶œ
                                if (
                                    len(cell_texts) > 2
                                    and cell_texts[2]
                                    and cell_texts[2].strip()
                                ):
                                    raw_reason = cell_texts[2].strip()
                                    if raw_reason not in [
                                        "REGTECH HTML Parse",
                                        "REGTECH Blacklist",
                                        "-",
                                        "N/A",
                                        "",
                                    ]:
                                        reason = raw_reason
                                        logger.info(f"âœ… RAW íƒì§€ë‚´ìš© ì¶”ì¶œ: ìœ„ì¹˜2 = {reason}")

                                # íƒì§€ì¼ (3ë²ˆì§¸ ìœ„ì¹˜)
                                if len(cell_texts) > 3 and cell_texts[3]:
                                    parsed_date = self._parse_date(cell_texts[3])
                                    if parsed_date:
                                        detection_date = parsed_date
                                        logger.info(
                                            f"âœ… RAW íƒì§€ì¼ ì¶”ì¶œ: ìœ„ì¹˜3 = {cell_texts[3]} -> {detection_date}"
                                        )

                                # í•´ì œì¼ (4ë²ˆì§¸ ìœ„ì¹˜)
                                if len(cell_texts) > 4 and cell_texts[4]:
                                    parsed_date = self._parse_date(cell_texts[4])
                                    if parsed_date:
                                        removal_date = parsed_date
                                        logger.info(
                                            f"âœ… RAW í•´ì œì¼ ì¶”ì¶œ: ìœ„ì¹˜4 = {cell_texts[4]} -> {removal_date}"
                                        )

                            # ë°±ì—…: í—¤ë” ê¸°ë°˜ ë‚ ì§œ ì¶”ì¶œ (RAW íŒŒì‹± ì‹¤íŒ¨ì‹œ)
                            if (
                                not detection_date
                                or not removal_date
                                or reason == "REGTECH HTML Parse"
                            ) and len(headers) > 0:
                                for i, cell_text in enumerate(cell_texts):
                                    if i < len(headers):
                                        header = headers[i]
                                        # íƒì§€ì¼ ê´€ë ¨ í—¤ë”ë“¤
                                        if not detection_date and any(
                                            keyword in header
                                            for keyword in [
                                                "ë“±ë¡",
                                                "reg",
                                                "íƒì§€",
                                                "detect",
                                                "ì¶”ê°€",
                                                "add",
                                            ]
                                        ):
                                            parsed_date = self._parse_date(cell_text)
                                            if parsed_date:
                                                detection_date = parsed_date
                                                logger.info(
                                                    f"âœ… HTML í—¤ë” íƒì§€ì¼: ì—´{i}({header}) = {cell_text} -> {detection_date}"
                                                )

                                        # í•´ì œì¼ ê´€ë ¨ í—¤ë”ë“¤
                                        elif not removal_date and any(
                                            keyword in header
                                            for keyword in [
                                                "í•´ì œ",
                                                "ì‚­ì œ",
                                                "del",
                                                "remove",
                                                "ë§Œë£Œ",
                                                "exp",
                                            ]
                                        ):
                                            parsed_date = self._parse_date(cell_text)
                                            if parsed_date:
                                                removal_date = parsed_date
                                                logger.info(
                                                    f"âœ… HTML í—¤ë” í•´ì œì¼: ì—´{i}({header}) = {cell_text} -> {removal_date}"
                                                )

                                        # ì‚¬ìœ /ë‚´ìš© ê´€ë ¨ í—¤ë”ë“¤
                                        elif reason == "REGTECH HTML Parse" and any(
                                            keyword in header
                                            for keyword in [
                                                "ì‚¬ìœ ",
                                                "reason",
                                                "ë‚´ìš©",
                                                "content",
                                                "ì„¤ëª…",
                                                "desc",
                                                "ìœ„í˜‘",
                                                "threat",
                                            ]
                                        ):
                                            if cell_text and len(cell_text.strip()) > 0:
                                                cell_content = cell_text.strip()
                                                if cell_content not in [
                                                    "REGTECH HTML Parse",
                                                    "REGTECH Blacklist",
                                                    "-",
                                                    "N/A",
                                                ]:
                                                    reason = cell_content
                                                    logger.info(
                                                        f"âœ… HTML í—¤ë” íƒì§€ë‚´ìš©: {header} = {reason}"
                                                    )

                            # ìµœì¢… ë°±ì—…: ìœ„ì¹˜ ê¸°ë°˜ ì¶”ì • (ëª¨ë“  íŒŒì‹± ì‹¤íŒ¨ì‹œ)
                            if not detection_date and len(cell_texts) > 1:
                                for i in range(1, min(len(cell_texts), 6)):
                                    parsed_date = self._parse_date(cell_texts[i])
                                    if parsed_date:
                                        detection_date = parsed_date
                                        logger.info(
                                            f"âœ… HTML ìœ„ì¹˜ê¸°ë°˜ íƒì§€ì¼: ì—´{i} = {cell_texts[i]} -> {detection_date}"
                                        )
                                        break

                            # ë¡œê·¸ìš© ì›ë³¸ ë°ì´í„°
                            logger.info(
                                f"ğŸ” HTML í–‰ {row_idx}: {cell_texts[:5]}..."
                            )  # ì²˜ìŒ 5ê°œ ì—´ë§Œ ë¡œê·¸

                            collected_data.append(
                                {
                                    "ip_address": ip_address,
                                    "source": "REGTECH",
                                    "reason": reason,
                                    "confidence_level": 75,
                                    "detection_count": 1,
                                    "is_active": True,
                                    "detection_date": detection_date,
                                    "removal_date": removal_date,
                                    "last_seen": datetime.now(),
                                    "country": self._extract_country_info(cell_texts),
                                    "raw_data": {  # ì›ë³¸ ë°ì´í„° JSON ì €ì¥
                                        "row_data": cell_texts[:10],
                                        "parsed_fields": {
                                            "ip": ip_address,
                                            "country": cell_texts[1]
                                            if len(cell_texts) > 1
                                            else None,
                                            "threat_description": reason,
                                            "detection_date": str(detection_date)
                                            if detection_date
                                            else None,
                                            "removal_date": str(removal_date)
                                            if removal_date
                                            else None,
                                            "raw_reason": cell_texts[2]
                                            if len(cell_texts) > 2
                                            else None,
                                        },
                                        "collection_timestamp": datetime.now().isoformat(),
                                        "parser_version": "enhanced_v1.0",
                                    },
                                }
                            )

            logger.info(f"ğŸ“„ HTML íŒŒì‹±: {len(collected_data)}ê°œ IP ì¶”ì¶œ (ë‚ ì§œ ì •ë³´ í¬í•¨)")
            return collected_data

        except Exception as e:
            logger.error(f"âŒ HTML íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []

    def _extract_country_info(self, cell_texts: List[str]) -> Optional[str]:
        """HTML í…Œì´ë¸” í–‰ì—ì„œ êµ­ê°€ ì •ë³´ ì¶”ì¶œ"""
        if not cell_texts:
            return None

        # êµ­ê°€ ì½”ë“œ/ì´ë¦„ì„ ì°¾ê¸° ìœ„í•œ íŒ¨í„´ë“¤
        country_patterns = {
            "KR": ["KR", "Korea", "í•œêµ­", "South Korea", "Republic of Korea"],
            "US": ["US", "USA", "United States", "ë¯¸êµ­", "America"],
            "CN": ["CN", "China", "ì¤‘êµ­", "CHN"],
            "JP": ["JP", "Japan", "ì¼ë³¸", "JPN"],
            "RU": ["RU", "Russia", "ëŸ¬ì‹œì•„", "Russian"],
            "DE": ["DE", "Germany", "ë…ì¼", "German"],
            "FR": ["FR", "France", "í”„ë‘ìŠ¤", "French"],
            "GB": ["GB", "UK", "United Kingdom", "ì˜êµ­", "Britain"],
            "IN": ["IN", "India", "ì¸ë„", "Indian"],
        }

        # ê° ì…€ì—ì„œ êµ­ê°€ ì •ë³´ ì°¾ê¸°
        for cell_text in cell_texts:
            if not cell_text or len(cell_text.strip()) < 2:
                continue

            cell_upper = cell_text.upper().strip()

            # êµ­ê°€ ì½”ë“œ ë§¤ì¹­
            for country_code, patterns in country_patterns.items():
                for pattern in patterns:
                    if pattern.upper() in cell_upper:
                        logger.info(f"âœ… êµ­ê°€ ì •ë³´ ë°œê²¬: '{cell_text}' -> {country_code}")
                        return country_code

            # 2ê¸€ì êµ­ê°€ ì½”ë“œ í˜•íƒœì¸ì§€ í™•ì¸
            if len(cell_text.strip()) == 2 and cell_text.strip().isalpha():
                country_code = cell_text.strip().upper()
                logger.info(f"âœ… êµ­ê°€ ì½”ë“œ ë°œê²¬: {country_code}")
                return country_code

        return None

    def _is_valid_ip(self, ip_str: str) -> bool:
        """IP ì£¼ì†Œ ìœ íš¨ì„± ê²€ì‚¬ - í–¥ìƒëœ ê²€ì¦"""
        try:
            import ipaddress

            ip_obj = ipaddress.ip_address(ip_str.strip())

            # ì‚¬ì„¤ IP ë° íŠ¹ìˆ˜ IP í•„í„°ë§
            if ip_obj.is_private or ip_obj.is_loopback or ip_obj.is_multicast:
                return False

            # IPv4 ìš°ì„ , IPv6 ì§€ì›
            return True

        except ValueError:
            return False

    def get_session_info(self) -> Dict[str, Any]:
        """ì„¸ì…˜ ì •ë³´ ë°˜í™˜ - í–¥ìƒëœ ì •ë³´"""
        return {
            "authenticated": self.authenticated,
            "cookies_count": len(self.session.cookies),
            "base_url": self.base_url,
            "cache_size": len(self._data_cache),
            "auth_cache_size": len(self._auth_cache),
            "performance_mode": "optimized",
            "last_activity": datetime.now().isoformat(),
            "rate_limiter": self.rate_limiter.get_stats(),  # Rate Limiter í†µê³„ ì¶”ê°€
        }

    def clear_cache(self):
        """ìºì‹œ ì •ë¦¬"""
        self._data_cache.clear()
        self._auth_cache.clear()
        logger.info("ğŸ§¹ ìºì‹œ ì •ë¦¬ ì™„ë£Œ")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
regtech_collector = RegtechCollector()
