# =============================================================================
# GitLab CI/CD: REGTECH Blacklist Intelligence Platform
# =============================================================================
# Version: 5.0.0 (2026-01)
# 
# Pipeline Architecture:
#   validate → lint → security → test → build → package → deploy → notify → cleanup
#
# Key Features:
#   - Air-Gap First: Git LFS as Docker Registry
#   - Offline Deployment: Single tar + install script
#   - Tag-based Releases: Semantic versioning with auto-changelog
#   - Comprehensive Testing: Unit, Integration, E2E (Pytest + Playwright)
#   - Security Scanning: pip-audit, npm audit, secret detection, Trivy
#   - Parallel Builds: DAG-based parallel Docker builds
#   - Smart Caching: File hash-based cache invalidation
#   - Rollback Support: Manual rollback to any tagged version
#
# Triggers:
#   - Push to main/master: Full pipeline
#   - Merge Request: Lint + Security + Test only
#   - Tags (v*): Full pipeline + Release creation
#   - Schedule: Security scan only
# =============================================================================

stages:
  - validate
  - lint
  - security
  - test
  - build
  - package
  - deploy
  - notify
  - cleanup

# =============================================================================
# GLOBAL VARIABLES
# =============================================================================
variables:
  # Git clone optimization for slow networks
  GIT_DEPTH: "1"
  GIT_STRATEGY: "clone"
  GIT_SUBMODULE_STRATEGY: "none"
  GIT_LFS_SKIP_SMUDGE: "1"
  GIT_CLEAN_FLAGS: "-ffdx -e node_modules/ -e .pytest_cache/ -e __pycache__/"
  
  # Git timeout settings (HTTP/HTTPS)
  GIT_HTTP_LOW_SPEED_LIMIT: "100"
  GIT_HTTP_LOW_SPEED_TIME: "600"
  
  # SSH timeout settings
  GIT_SSH_COMMAND: "ssh -o ConnectTimeout=120 -o ServerAliveInterval=30 -o ServerAliveCountMax=10 -o TCPKeepAlive=yes"

  # GitLab Container Registry
  CI_REGISTRY: "registry.jclee.me"
  CI_REGISTRY_IMAGE: "registry.jclee.me/nextrade/blacklist"

  # Component image names
  IMAGE_POSTGRES: "${CI_REGISTRY_IMAGE}/blacklist-postgres"
  IMAGE_REDIS: "${CI_REGISTRY_IMAGE}/blacklist-redis"
  IMAGE_COLLECTOR: "${CI_REGISTRY_IMAGE}/blacklist-collector"
  IMAGE_APP: "${CI_REGISTRY_IMAGE}/blacklist-app"
  IMAGE_FRONTEND: "${CI_REGISTRY_IMAGE}/blacklist-frontend"

  # Version management (injected into Docker images)
  APP_VERSION: ""
  COMMIT_HASH: "${CI_COMMIT_SHA}"
  BUILD_NUMBER: "${CI_PIPELINE_ID}"
  
  # Cache keys (file hash-based for optimal invalidation)
  PIP_CACHE_KEY: "pip-v2"
  NPM_CACHE_KEY: "npm-v2"

# =============================================================================
# GLOBAL CACHE CONFIGURATION
# =============================================================================
.pip-cache: &pip-cache
  cache:
    key:
      files:
        - app/requirements.txt
        - collector/requirements.txt
      prefix: ${PIP_CACHE_KEY}
    paths:
      - .pip-cache/
    policy: pull-push

.npm-cache: &npm-cache
  cache:
    key:
      files:
        - frontend/package-lock.json
      prefix: ${NPM_CACHE_KEY}
    paths:
      - frontend/node_modules/
    policy: pull-push

# =============================================================================
# WORKFLOW RULES - Pipeline Trigger Conditions
# =============================================================================
workflow:
  rules:
    # Tag releases (v1.0.0, v2.1.0-beta, etc.)
    - if: $CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+/
      variables:
        PIPELINE_TYPE: "release"
    # Main/Master branch
    - if: $CI_COMMIT_BRANCH == "main" || $CI_COMMIT_BRANCH == "master"
      variables:
        PIPELINE_TYPE: "production"
    # Merge Requests
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      variables:
        PIPELINE_TYPE: "merge_request"
    # Scheduled pipelines
    - if: $CI_PIPELINE_SOURCE == "schedule"
      variables:
        PIPELINE_TYPE: "schedule"
    # Manual/Web trigger
    - if: $CI_PIPELINE_SOURCE == "web"
      variables:
        PIPELINE_TYPE: "manual"

# =============================================================================
# VALIDATE STAGE
# =============================================================================

validate:environment:
  stage: validate
  image: alpine:latest
  script:
    - 'echo "Pipeline Type: $PIPELINE_TYPE"'
    - 'echo "Branch: ${CI_COMMIT_BRANCH:-N/A}"'
    - 'echo "Tag: ${CI_COMMIT_TAG:-N/A}"'
    - 'echo "Registry: $CI_REGISTRY"'
    - 'echo "Commit: $CI_COMMIT_SHORT_SHA"'
    - 'if [ -f VERSION ]; then echo "App Version: $(cat VERSION)"; fi'
  rules:
    - when: always

# Prevent builds with uncommitted changes (catches forgotten commits)
validate:clean-tree:
  stage: validate
  image: alpine/git:latest
  script:
    - |
      echo "Checking for uncommitted changes..."
      if ! git diff-index --quiet HEAD -- 2>/dev/null; then
        echo "❌ ERROR: Uncommitted changes detected!"
        echo "Files with uncommitted changes:"
        git status --short
        echo ""
        echo "Please commit all changes before pushing."
        exit 1
      fi
      echo "✅ Working tree is clean"
  rules:
    - if: $CI_PIPELINE_SOURCE == "push"
    - if: $CI_COMMIT_TAG
  allow_failure: false

# =============================================================================
# LINT STAGE - Code Quality Checks
# =============================================================================

lint:python:
  stage: lint
  image: python:3.11-slim
  timeout: 5m
  <<: *pip-cache
  variables:
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  before_script:
    - pip install ruff --quiet
  script:
    - echo "Linting Python code with Ruff..."
    - ruff check app/ collector/ --output-format=gitlab > ruff-report.json
    - ruff check app/ collector/ --statistics
  artifacts:
    reports:
      codequality: ruff-report.json
    expire_in: 7 days
  allow_failure: true

lint:typescript:
  stage: lint
  image: node:20-slim
  timeout: 5m
  <<: *npm-cache
  script:
    - cd frontend
    - npm ci --prefer-offline --legacy-peer-deps 2>/dev/null || npm install --legacy-peer-deps
    - echo "Linting TypeScript code with ESLint..."
    - npm run lint -- --format gitlab > ../eslint-report.json
    - npm run lint
  artifacts:
    reports:
      codequality: eslint-report.json
    expire_in: 7 days
  allow_failure: true

lint:dockerfile:
  stage: lint
  image: hadolint/hadolint:latest-debian
  timeout: 3m
  script:
    - echo "Linting Dockerfiles with Hadolint..."
    - hadolint app/Dockerfile collector/Dockerfile frontend/Dockerfile postgres/Dockerfile redis/Dockerfile --format gitlab_codeclimate > hadolint-report.json
    - hadolint app/Dockerfile collector/Dockerfile frontend/Dockerfile postgres/Dockerfile redis/Dockerfile
  artifacts:
    reports:
      codequality: hadolint-report.json
    expire_in: 7 days
  allow_failure: true

# =============================================================================
# SECURITY STAGE - Vulnerability Scanning
# =============================================================================

security:python-scan:
  stage: security
  image: python:3.11-slim
  timeout: 10m
  <<: *pip-cache
  variables:
    GIT_LFS_SKIP_SMUDGE: "1"
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
  before_script:
    - python3 -m venv .venv && source .venv/bin/activate
    - pip install pip-audit --quiet
  script:
    - pip-audit -r app/requirements.txt --format json > app-audit.json
    - pip-audit -r collector/requirements.txt --format json > collector-audit.json
    - echo "✅ Security scan completed"
  artifacts:
    paths:
      - "*-audit.json"
    expire_in: 30 days
    when: always
  allow_failure: false

security:javascript-scan:
  stage: security
  image: node:20-slim
  timeout: 10m
  <<: *npm-cache
  variables:
    GIT_LFS_SKIP_SMUDGE: "1"
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
  script:
    - cd frontend
    - npm ci --prefer-offline --legacy-peer-deps 2>/dev/null || npm install --legacy-peer-deps
    - npm audit --json > ../frontend-audit.json
    - npm audit --audit-level=moderate
  artifacts:
    paths:
      - "*-audit.json"
    expire_in: 30 days
    when: always
  allow_failure: true

security:secret-detection:
  stage: security
  image: python:3.11-slim
  timeout: 5m
  variables:
    GIT_LFS_SKIP_SMUDGE: "1"
  before_script:
    - pip install detect-secrets --quiet
  script:
    - detect-secrets scan --all-files --exclude-files 'node_modules|\.git|dist/images' > secrets-report.json
    - |
      if grep -q '"results": {}' secrets-report.json; then
        echo "No secrets detected"
      else
        echo "Potential secrets found - review secrets-report.json"
        cat secrets-report.json
      fi
  artifacts:
    paths:
      - secrets-report.json
    expire_in: 30 days
    when: always
  allow_failure: true

security:container-scan:
  stage: security
  image: aquasec/trivy:latest
  timeout: 15m
  variables:
    GIT_STRATEGY: clone
    TRIVY_NO_PROGRESS: "true"
    TRIVY_CACHE_DIR: ".trivycache/"
  before_script:
    - trivy --version
  script:
    # Trivy only accepts single target - scan each directory separately
    - trivy fs --exit-code 0 --severity HIGH,CRITICAL --format json -o trivy-app.json app/
    - trivy fs --exit-code 0 --severity HIGH,CRITICAL --format json -o trivy-collector.json collector/
    - trivy fs --exit-code 0 --severity HIGH,CRITICAL --format json -o trivy-frontend.json frontend/
    # Merge results into single report
    - 'echo "{\"Results\": $(cat trivy-app.json trivy-collector.json trivy-frontend.json | jq -s ''[.[].Results // []] | add'')}" > trivy-fs-report.json'
    # Critical check (allow failure)
    - trivy fs --exit-code 1 --severity CRITICAL app/
    - trivy fs --exit-code 1 --severity CRITICAL collector/
    - trivy fs --exit-code 1 --severity CRITICAL frontend/
  artifacts:
    paths:
      - trivy-fs-report.json
    reports:
      container_scanning: trivy-fs-report.json
    expire_in: 30 days
    when: always
  allow_failure: true
  rules:
    - if: $PIPELINE_TYPE == "production" || $PIPELINE_TYPE == "release"
      when: always
    - if: $PIPELINE_TYPE == "schedule"
      when: always
    - when: never

test:backend-unit:
  stage: test
  image: python:3.11-slim
  timeout: 20m
  <<: *pip-cache
  variables:
    GIT_LFS_SKIP_SMUDGE: "1"
    PYTHONPATH: "${CI_PROJECT_DIR}:${CI_PROJECT_DIR}/app"
    CREDENTIAL_MASTER_KEY: "test_master_key_for_ci_only_do_not_use_in_production"
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
  before_script:
    - python3 -m venv .venv && source .venv/bin/activate
    - pip install --upgrade pip --quiet
    - pip install -r app/requirements.txt pytest pytest-cov pytest-mock pytest-flask pytest-html --quiet
  script:
    - source .venv/bin/activate
    - export PYTHONPATH="${CI_PROJECT_DIR}:${CI_PROJECT_DIR}/app:$PYTHONPATH"
    - |
      pytest tests/unit -v \
        --cov=app/core \
        --cov-report=xml:coverage.xml \
        --cov-report=html:htmlcov \
        --cov-report=term \
        --junitxml=junit-backend-unit.xml \
        --html=report-backend-unit.html \
        --self-contained-html
  rules:
    - if: $PIPELINE_TYPE == "merge_request"
      allow_failure: false
    - if: $PIPELINE_TYPE == "production" || $PIPELINE_TYPE == "release"
      allow_failure: true
  artifacts:
    paths:
      - coverage.xml
      - htmlcov/
      - junit-backend-unit.xml
      - report-backend-unit.html
    reports:
      junit: junit-backend-unit.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml
    expire_in: 30 days
    when: always
  coverage: '/(?i)total.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/'

test:backend-integration:
  stage: test
  image: python:3.11-slim
  timeout: 15m
  <<: *pip-cache
  services:
    - name: postgres:15-alpine
      alias: postgres
    - name: redis:7-alpine
      alias: redis
  variables:
    GIT_LFS_SKIP_SMUDGE: "1"
    PYTHONPATH: "${CI_PROJECT_DIR}:${CI_PROJECT_DIR}/app"
    POSTGRES_HOST: postgres
    POSTGRES_PORT: "5432"
    POSTGRES_DB: blacklist_test
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
    REDIS_HOST: redis
    REDIS_PORT: "6379"
    CREDENTIAL_MASTER_KEY: "test_master_key_for_ci_only_do_not_use_in_production"
    PIP_CACHE_DIR: "$CI_PROJECT_DIR/.pip-cache"
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
  before_script:
    - apt-get update -qq && apt-get install -y -qq postgresql-client > /dev/null 2>&1 || true
    - |
      for i in $(seq 1 30); do
        pg_isready -h postgres -p 5432 -U postgres > /dev/null 2>&1 && break
        sleep 2
      done
    - python3 -m venv .venv && source .venv/bin/activate
    - pip install --upgrade pip --quiet
    - pip install -r app/requirements.txt pytest pytest-mock pytest-flask pytest-html pytest-timeout --quiet
  script:
    - source .venv/bin/activate
    - export PYTHONPATH="${CI_PROJECT_DIR}:${CI_PROJECT_DIR}/app:$PYTHONPATH"
    - |
      pytest tests/integration -v \
        --timeout=30 \
        --timeout-method=thread \
        --junitxml=junit-backend-integration.xml \
        --html=report-backend-integration.html \
        --self-contained-html
  rules:
    - if: $PIPELINE_TYPE == "merge_request"
      allow_failure: false
    - if: $PIPELINE_TYPE == "production" || $PIPELINE_TYPE == "release"
      allow_failure: true
  artifacts:
    paths:
      - junit-backend-integration.xml
      - report-backend-integration.html
    reports:
      junit: junit-backend-integration.xml
    expire_in: 30 days
    when: always

test:frontend-unit:
  stage: test
  image: node:20-slim
  timeout: 15m
  <<: *npm-cache
  variables:
    GIT_LFS_SKIP_SMUDGE: "1"
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
  script:
    - cd frontend
    - npm ci --prefer-offline --silent
    - npm run test -- --reporter=junit --reporter=default --outputFile=../junit-frontend-unit.xml
    - npm run test:coverage
  artifacts:
    paths:
      - junit-frontend-unit.xml
      - frontend/coverage/
    reports:
      junit: junit-frontend-unit.xml
    expire_in: 30 days
    when: always
  rules:
    - if: $PIPELINE_TYPE == "merge_request"
      changes:
        - frontend/**/*
      when: always
    - if: $PIPELINE_TYPE == "production" || $PIPELINE_TYPE == "release"
      changes:
        - frontend/**/*
      when: always
    - when: never

test:frontend-e2e:
  stage: test
  image: mcr.microsoft.com/playwright:v1.57.0-jammy
  timeout: 20m
  <<: *npm-cache
  variables:
    GIT_LFS_SKIP_SMUDGE: "1"
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
  script:
    - cd frontend
    - npm ci --prefer-offline --silent
    - npx playwright install --with-deps chromium
    - npm run test:e2e -- --reporter=junit --reporter=html
  artifacts:
    paths:
      - frontend/playwright-report/
      - frontend/test-results/
    expire_in: 30 days
    when: always
  rules:
    - if: $PIPELINE_TYPE == "release"
      when: always
    - if: $PIPELINE_TYPE == "production"
      when: manual
    - when: never
  allow_failure: true

# =============================================================================
# BUILD STAGE - Docker Image Builds
# =============================================================================

.docker-build-template:
  stage: build
  image: docker:24.0.7
  services:
    - docker:24.0.7-dind
  needs: ["validate:environment"]
  timeout: 20m
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure
      - script_failure
  variables:
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: "$DOCKER_TLS_CERTDIR/client"
    GIT_LFS_SKIP_SMUDGE: "1"
  before_script:
    - docker info || (echo "Docker daemon not available" && exit 1)
    - echo "$CI_JOB_TOKEN" | docker login -u gitlab-ci-token --password-stdin $CI_REGISTRY
    - export COMMIT_SHORT=$(echo $CI_COMMIT_SHA | cut -c1-8)
    - export BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
    - export VERSION_TAG="${CI_COMMIT_TAG:-latest}"
    - |
      if [ -f VERSION ]; then
        export APP_VERSION="$(cat VERSION)-${CI_PIPELINE_ID}-${COMMIT_SHORT}"
      else
        export APP_VERSION="0.0.0-dev"
      fi
  rules:
    - if: $PIPELINE_TYPE == "merge_request"
      when: never
    - if: $PIPELINE_TYPE == "production" || $PIPELINE_TYPE == "release"
      when: always
    - if: $PIPELINE_TYPE == "manual"
      when: always
    - when: never

build:postgres:
  extends: .docker-build-template
  script:
    - |
      DOCKER_BUILDKIT=1 docker build \
        --build-arg "BUILD_DATE=${BUILD_DATE}" \
        --build-arg "VCS_REF=${CI_COMMIT_SHA}" \
        -t "${IMAGE_POSTGRES}:${VERSION_TAG}" \
        -t "${IMAGE_POSTGRES}:${COMMIT_SHORT}" \
        -t "${IMAGE_POSTGRES}:latest" \
        postgres/
    - docker push "${IMAGE_POSTGRES}:${VERSION_TAG}"
    - docker push "${IMAGE_POSTGRES}:${COMMIT_SHORT}"
    - docker push "${IMAGE_POSTGRES}:latest"

build:redis:
  extends: .docker-build-template
  script:
    - |
      DOCKER_BUILDKIT=1 docker build \
        --build-arg "BUILD_DATE=${BUILD_DATE}" \
        --build-arg "VCS_REF=${CI_COMMIT_SHA}" \
        -t "${IMAGE_REDIS}:${VERSION_TAG}" \
        -t "${IMAGE_REDIS}:${COMMIT_SHORT}" \
        -t "${IMAGE_REDIS}:latest" \
        redis/
    - docker push "${IMAGE_REDIS}:${VERSION_TAG}"
    - docker push "${IMAGE_REDIS}:${COMMIT_SHORT}"
    - docker push "${IMAGE_REDIS}:latest"

build:collector:
  extends: .docker-build-template
  script:
    - cd collector
    - |
      DOCKER_BUILDKIT=1 docker build \
        --build-arg "BUILD_DATE=${BUILD_DATE}" \
        --build-arg "VCS_REF=${CI_COMMIT_SHA}" \
        -t "${IMAGE_COLLECTOR}:${VERSION_TAG}" \
        -t "${IMAGE_COLLECTOR}:${COMMIT_SHORT}" \
        -t "${IMAGE_COLLECTOR}:latest" \
        .
    - docker push "${IMAGE_COLLECTOR}:${VERSION_TAG}"
    - docker push "${IMAGE_COLLECTOR}:${COMMIT_SHORT}"
    - docker push "${IMAGE_COLLECTOR}:latest"

build:app:
  extends: .docker-build-template
  script:
    - |
      DOCKER_BUILDKIT=1 docker build \
        --build-arg "BUILD_DATE=${BUILD_DATE}" \
        --build-arg "VCS_REF=${CI_COMMIT_SHA}" \
        --build-arg "APP_VERSION=${APP_VERSION}" \
        --build-arg "COMMIT_HASH=${CI_COMMIT_SHA}" \
        --build-arg "BUILD_NUMBER=${CI_PIPELINE_ID}" \
        -t "${IMAGE_APP}:${VERSION_TAG}" \
        -t "${IMAGE_APP}:${COMMIT_SHORT}" \
        -t "${IMAGE_APP}:latest" \
        app/
    - docker push "${IMAGE_APP}:${VERSION_TAG}"
    - docker push "${IMAGE_APP}:${COMMIT_SHORT}"
    - docker push "${IMAGE_APP}:latest"

build:frontend:
  extends: .docker-build-template
  script:
    - |
      DOCKER_BUILDKIT=1 docker build \
        --build-arg "BUILD_DATE=${BUILD_DATE}" \
        --build-arg "VCS_REF=${CI_COMMIT_SHA}" \
        -t "${IMAGE_FRONTEND}:${VERSION_TAG}" \
        -t "${IMAGE_FRONTEND}:${COMMIT_SHORT}" \
        -t "${IMAGE_FRONTEND}:latest" \
        frontend/
    - docker push "${IMAGE_FRONTEND}:${VERSION_TAG}"
    - docker push "${IMAGE_FRONTEND}:${COMMIT_SHORT}"
    - docker push "${IMAGE_FRONTEND}:latest"

# =============================================================================
# PACKAGE STAGE - Air-Gap Image Export & Git LFS Push
# =============================================================================

package:airgap-images:
  stage: package
  image: docker:24.0.7
  services:
    - docker:24.0.7-dind
  needs:
    - job: build:postgres
      optional: true
    - job: build:redis
      optional: true
    - job: build:collector
      optional: true
    - job: build:app
      optional: true
    - job: build:frontend
      optional: true
  timeout: 45m
  variables:
    DOCKER_HOST: tcp://docker:2376
    DOCKER_TLS_CERTDIR: "/certs"
    DOCKER_TLS_VERIFY: 1
    DOCKER_CERT_PATH: "$DOCKER_TLS_CERTDIR/client"
    GIT_LFS_SKIP_SMUDGE: "1"
    GIT_DEPTH: "0"
  before_script:
    - |
      if command -v apk >/dev/null 2>&1; then
        apk add --no-cache git openssh-client
      elif command -v apt-get >/dev/null 2>&1; then
        sudo apt-get update -qq && sudo apt-get install -y -qq git openssh-client
      fi
    - docker info || exit 1
    - git config --global user.email "gitlab-ci@jclee.me"
    - git config --global user.name "GitLab CI"
    - git config --global http.postBuffer 524288000
    - git remote set-url origin "https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.jclee.me/${CI_PROJECT_PATH}.git"
    - git fetch origin --prune
    - echo "$CI_JOB_TOKEN" | docker login -u gitlab-ci-token --password-stdin $CI_REGISTRY
    - export VERSION_TAG="${CI_COMMIT_TAG:-latest}"
    - export COMMIT_SHORT=$(echo $CI_COMMIT_SHA | cut -c1-8)
  script:
    - docker pull "${IMAGE_POSTGRES}:${COMMIT_SHORT}"
    - docker pull "${IMAGE_REDIS}:${COMMIT_SHORT}"
    - docker pull "${IMAGE_COLLECTOR}:${COMMIT_SHORT}"
    - docker pull "${IMAGE_APP}:${COMMIT_SHORT}"
    - docker pull "${IMAGE_FRONTEND}:${COMMIT_SHORT}"
    
    - docker tag "${IMAGE_POSTGRES}:${COMMIT_SHORT}" blacklist-postgres:latest
    - docker tag "${IMAGE_REDIS}:${COMMIT_SHORT}" blacklist-redis:latest
    - docker tag "${IMAGE_COLLECTOR}:${COMMIT_SHORT}" blacklist-collector:latest
    - docker tag "${IMAGE_APP}:${COMMIT_SHORT}" blacklist-app:latest
    - docker tag "${IMAGE_FRONTEND}:${COMMIT_SHORT}" blacklist-frontend:latest
    
    - mkdir -p dist/images
    - |
      docker save blacklist-postgres:latest | gzip > dist/images/blacklist-postgres.tar.gz &
      docker save blacklist-redis:latest | gzip > dist/images/blacklist-redis.tar.gz &
      docker save blacklist-collector:latest | gzip > dist/images/blacklist-collector.tar.gz &
      docker save blacklist-app:latest | gzip > dist/images/blacklist-app.tar.gz &
      docker save blacklist-frontend:latest | gzip > dist/images/blacklist-frontend.tar.gz &
      wait
    
    - |
      cd dist/images
      sha256sum *.tar.gz > checksums.sha256
      cd ../..
    
    - ls -lh dist/images/
    
    # Create single airgap archive
    - cp docker-compose.yml dist/
    
    # Download offline prerequisites (Docker + Compose)
    - mkdir -p dist/prereqs
    - wget -q -O dist/prereqs/docker-24.0.7.tgz https://download.docker.com/linux/static/stable/x86_64/docker-24.0.7.tgz
    - wget -q -O dist/prereqs/docker-compose-linux-x86_64 https://github.com/docker/compose/releases/download/v2.24.5/docker-compose-linux-x86_64
    - chmod +x dist/prereqs/docker-compose-linux-x86_64
    
    # Use the full-featured install.sh from repo (273 lines with preflight, checksum, SSL, health checks)
    - chmod +x dist/install.sh
    
    - |
      if [ "$VERSION_TAG" != "latest" ]; then
        PACKAGE_NAME="blacklist-airgap-${VERSION_TAG}.tar.gz"
      else
        PACKAGE_NAME="blacklist-airgap-${COMMIT_SHORT}.tar.gz"
      fi
      echo "Creating package: $PACKAGE_NAME"
      tar -czf "$PACKAGE_NAME" -C dist images install.sh docker-compose.yml prereqs
      mv "$PACKAGE_NAME" dist/

    - rm -rf dist/images dist/docker-compose.yml dist/prereqs
    
    # Push to airgap branch
    - |
      git checkout -B airgap
      rm -rf app collector frontend postgres redis scripts docs k8s tests .opencode
      rm -f .gitlab-ci.yml docker-compose.yml Makefile README.md VERSION .gitignore .editorconfig .ruff.toml *.tar.gz 2>/dev/null || true
      cp dist/install.sh .
      cp dist/*.tar.gz .
      git add -A
      git commit -m "chore: update airgap package ($PACKAGE_NAME)" || true
      git push origin airgap --force
    
    - 'echo "Air-gap package pushed to airgap branch"'
  rules:
    - if: $PIPELINE_TYPE == "production" || $PIPELINE_TYPE == "release"
      when: always
    - if: $PIPELINE_TYPE == "manual"
      when: always
    - when: never
  allow_failure: false

# =============================================================================
# DEPLOY STAGE - Environment Deployments
# =============================================================================

deploy:local:
  stage: deploy
  needs: ["package:airgap-images"]
  variables:
    GIT_STRATEGY: none
  script:
    - |
      if [ -n "$LOCAL_DEPLOY_HOST" ]; then
        ssh -o StrictHostKeyChecking=no $LOCAL_DEPLOY_USER@$LOCAL_DEPLOY_HOST \
          "cd /opt/blacklist && git pull && ./install.sh"
      else
        echo "LOCAL_DEPLOY_HOST not configured - skipping"
      fi
  rules:
    - if: $PIPELINE_TYPE == "production"
      when: manual
    - when: never
  allow_failure: true

deploy:airgap:
  stage: deploy
  needs: ["package:airgap-images"]
  variables:
    GIT_STRATEGY: none
  script:
    - 'echo "=== Air-Gap Deployment Package Ready ==="'
    - 'echo ""'
    - 'echo "1. Clone airgap branch:"'
    - 'echo "   git clone -b airgap ssh://git@gitlab.jclee.me:2022/${CI_PROJECT_PATH}.git"'
    - 'echo ""'
    - 'echo "2. Transfer to air-gapped environment"'
    - 'echo ""'
    - 'echo \"3. Deploy:\"'
    - 'echo \"   ./install.sh\"'
    - 'echo ""'
    - 'echo "Images included:"'
    - 'echo "  - blacklist-postgres"'
    - 'echo "  - blacklist-redis"'
    - 'echo "  - blacklist-collector"'
    - 'echo "  - blacklist-app"'
    - 'echo "  - blacklist-frontend"'
  rules:
    - if: $PIPELINE_TYPE == "production" || $PIPELINE_TYPE == "release"
      when: always
    - when: never

deploy:rollback:
  stage: deploy
  variables:
    GIT_STRATEGY: none
    ROLLBACK_TAG: ""
  script:
    - |
      if [ -z "$ROLLBACK_TAG" ]; then
        echo "ERROR: ROLLBACK_TAG variable must be set"
        echo "Usage: Run this job manually with ROLLBACK_TAG=v3.0.0"
        exit 1
      fi
    - echo "Rolling back to version $ROLLBACK_TAG"
    - |
      if [ -n "$LOCAL_DEPLOY_HOST" ]; then
        ssh -o StrictHostKeyChecking=no $LOCAL_DEPLOY_USER@$LOCAL_DEPLOY_HOST \
          "cd /opt/blacklist && git fetch --tags && git checkout $ROLLBACK_TAG && ./install.sh"
        echo "Rollback to $ROLLBACK_TAG completed successfully"
      else
        echo "LOCAL_DEPLOY_HOST not configured"
        echo "Manual rollback required:"
        echo "  git checkout $ROLLBACK_TAG"
        echo "  ./install.sh"
      fi
  rules:
    - if: $PIPELINE_TYPE == "production"
      when: manual
    - when: never
  allow_failure: false

# =============================================================================
# RELEASE STAGE - Tag-based Releases
# =============================================================================

release:create:
  stage: deploy
  image: registry.gitlab.com/gitlab-org/release-cli:latest
  needs: ["package:airgap-images"]
  variables:
    GIT_STRATEGY: none
  script:
    - echo "Creating release for ${CI_COMMIT_TAG}"
  release:
    tag_name: $CI_COMMIT_TAG
    name: "Release $CI_COMMIT_TAG"
    description: |
      ## REGTECH Blacklist v${CI_COMMIT_TAG}
      
      ### Installation
      \`\`\`bash
      git clone -b airgap ssh://git@gitlab.jclee.me:2022/${CI_PROJECT_PATH}.git
      cd blacklist && ./install.sh
      \`\`\`
      
      ### Changes
      See [CHANGELOG.md](CHANGELOG.md) for details.
      
      Build: #${CI_PIPELINE_ID} | Commit: ${CI_COMMIT_SHORT_SHA}
  rules:
    - if: $PIPELINE_TYPE == "release"
      when: always
    - when: never

# =============================================================================
# NOTIFY STAGE - Pipeline Notifications
# =============================================================================

notify:slack:
  stage: notify
  image: curlimages/curl:latest
  variables:
    GIT_STRATEGY: none
  script:
    - |
      if [ -n "$SLACK_WEBHOOK_URL" ]; then
        APP_VER=$(cat VERSION 2>/dev/null || echo "unknown")
        if [ "$CI_JOB_STATUS" = "success" ]; then
          COLOR="good"
          STATUS="SUCCESS"
        else
          COLOR="danger"
          STATUS="FAILED"
        fi
        curl -X POST -H 'Content-type: application/json' \
          --data "{\"attachments\":[{\"color\":\"${COLOR}\",\"title\":\"Pipeline ${STATUS}: ${CI_PROJECT_NAME}\",\"text\":\"Branch: ${CI_COMMIT_BRANCH}\\nVersion: ${APP_VER}\\nPipeline: #${CI_PIPELINE_ID}\",\"footer\":\"GitLab CI/CD\"}]}" \
          "$SLACK_WEBHOOK_URL"
      fi
  rules:
    - if: $PIPELINE_TYPE == "production" || $PIPELINE_TYPE == "release"
      when: always
    - when: never
  allow_failure: true

# =============================================================================
# CLEANUP STAGE - Registry Maintenance
# =============================================================================

cleanup:registry:
  stage: cleanup
  image: alpine:latest
  before_script:
    - apk add --no-cache curl jq
  script:
    - |
      for component in postgres redis collector app frontend; do
        REPO_ID=$(curl -s --header "PRIVATE-TOKEN: $GITLAB_API_TOKEN" \
          "https://gitlab.jclee.me/api/v4/projects/${CI_PROJECT_ID}/registry/repositories" | \
          jq -r ".[] | select(.name | contains(\"blacklist-${component}\")) | .id")
        if [ -n "$REPO_ID" ] && [ "$REPO_ID" != "null" ]; then
          echo "Cleaning old tags for blacklist-${component} (repo_id: $REPO_ID, keep last 10)"
          # Bulk delete: keep last 10 tags, remove those older than 7 days
          DELETE_RESULT=$(curl -s -w "%{http_code}" -o /tmp/delete_response.json \
            --request DELETE \
            --header "PRIVATE-TOKEN: $GITLAB_API_TOKEN" \
            "https://gitlab.jclee.me/api/v4/projects/${CI_PROJECT_ID}/registry/repositories/${REPO_ID}/tags?keep_n=10&older_than=7d")
          if [ "$DELETE_RESULT" = "200" ] || [ "$DELETE_RESULT" = "202" ]; then
            echo "  ✓ Cleanup scheduled for blacklist-${component}"
          elif [ "$DELETE_RESULT" = "400" ]; then
            echo "  - No tags to delete for blacklist-${component}"
          else
            echo "  ✗ Failed to cleanup blacklist-${component} (HTTP $DELETE_RESULT)"
            cat /tmp/delete_response.json 2>/dev/null || true
          fi
        else
          echo "  - Repository blacklist-${component} not found, skipping"
        fi
      done
  rules:
    - if: $PIPELINE_TYPE == "production"
      when: always
    - if: $PIPELINE_TYPE == "schedule"
      when: always
    - when: never
  allow_failure: true

cleanup:docker:
  stage: cleanup
  variables:
    GIT_STRATEGY: none
  script:
    - docker system prune -f --volumes 2>/dev/null || true
    - docker image prune -f --filter "until=168h" 2>/dev/null || true
  rules:
    - if: $PIPELINE_TYPE == "production"
      when: always
    - when: never
  allow_failure: true

# =============================================================================
# OPENCODE AI REVIEW (via devops/gitlab-opencode component)
# =============================================================================
# include:
#   - component: $CI_SERVER_FQDN/opencode/gitlab-opencode/opencode@main
#     inputs:
#       config_dir: ${CI_PROJECT_DIR}
#       auth_json: $OPENCODE_AUTH_JSON
#       message: "Review this merge request. Focus on code quality, security issues, and suggest improvements."
#       stage: validate
#       job_prefix: "opencode-review"

# opencode-review:run:
#   rules:
#     - if: $CI_PIPELINE_SOURCE == "merge_request_event"
